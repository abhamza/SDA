\part{Graphes}

\begin{frame}{Plan}

\tableofcontents

\end{frame}

\section{Définitions}

\begin{frame}{Graphes}

\begin{itemize}
\item Un \alert{graphe (dirigé)}  est un couple $(V,E)$ où:
\begin{itemize}
\item $V$ est un ensemble de n\oe uds ({\it nodes}), ou sommets ({\it vertices}) et
\item $E\subseteq V\times V$ est un ensemble d'arcs, ou arêtes ({\it edges}).
\end{itemize}
\item Un graphe \alert{non dirigé} est caractérisé par une relation symmétrique entre les sommets
\begin{itemize}
\item Une arête est un ensemble $e=\{u,v\}$ de deux sommets
\item On la notera tout de même $(u,v)$ (équivalent à $(v,u)$). 
\end{itemize}

\item Applications: modélisation de:
\begin{itemize}
\item Réseaux sociaux
\item Réseaux informatiques
\item World Wide Web
\item Cartes routières
\item \ldots
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Terminologie: graphe non dirigé}

\centerline{\includegraphics[width=3cm]{Figures/07-exemple-graphenondirige.pdf}}
{\small $$V=\{1,2,3,4,5\}, E=\{(1,2),(1,5),(2,5),(2,3),(3,4),(4,5)\}$$}
\begin{itemize}
\item Deux n\oe uds sont \alert{adjacents} s'ils sont liés par une même arête
\item Une arête $(v_1,v_2)$ est dite \alert{incidente} aux n\oe uds $v_1$ et $v_2$
\item Le \alert{degré} d'un n\oe ud est égal au nombre de ses arêtes incidentes
\item Le \alert{degrée d'un graphe} est le nombre maximal d'arêtes incidentes à tout sommet.
\item Un graphe est \alert{connexe} s'il existe un chemin de tout sommet à tout autre.
\item Une \alert{composante connexe} d'un graphe non orienté est un sous-graphe connexe
  maximal de ce graphe
\end{itemize}

\end{frame}

\begin{frame}{Terminologie: graphe dirigé}

\centerline{\includegraphics[width=4cm]{Figures/07-exemple-graphedirige.pdf}}
{\small $$V=\{1,2,3,4,5,6\}, E=\{(1,2),(1,4),(2,5),(3,5),(3,6),(4,2),(5,4),(6,6)\}$$}
\begin{itemize}
\item Une arête $(v_1,v_2)$ possède l'\alert{origine} $v_1$ et la \alert{destination}
  $v_2$. Cette arête est \alert{sortante} pour $v_1$ et \alert{entrante} pour $v_2$
\item Le degré \alert{entrant} ({\it in-degree}) et le degré \alert{sortant}
  ({\it out-degree}) d'un n\oe ud $v$ sont respectivement égaux aux nombres d'arêtes entrantes et d'arêtes sortantes de $v$
\item Un graphe est \alert{acyclique} s'il n'y a aucun cycle, c'est-à-dire
  s'il n'est pas possible de suivre les arêtes du graphes à partir
  d'un sommet $x$ et de revenir à ce même sommet $x$
\end{itemize}

\end{frame}

\begin{frame}{Type de graphes}
\begin{itemize}
\item Un graphe est \alert{simple} s'il ne possède pas de boucle composée d'une seule arête, c'est-à-dire tel que:
$$\forall v \in V: (v,v)\notin E$$
\item Un \alert{arbre} est un graphe acyclique connexe
\item Un \alert{multigraphe} est une généralisation des graphes pour laquelle
  il est permis de définir plus d'une arête liant un sommet à un autre

\bigskip

\item Un graphe est \alert{pondéré} si les arêtes sont annotées par des \alert{poids}
\begin{itemize}
\item Exemple: réseau entre villes avec comme poids la distance entre
  les villes, réseau internet avec comme poids la bande passante entre routeurs, etc.
\end{itemize}
\end{itemize}
\end{frame}

\section{Représentation des graphes}

\begin{frame}{Représentation I: listes d'adjacences}

Un objet $G$ de type graphe est composé:
\begin{itemize}
\item d'une liste de n\oe uds $G.V=\{1,2,\ldots,|V|\}$
\item d'un tableau $G.Adj$ de $|V|$ listes tel que:
\begin{itemize}
\item Chaque sommet $u\in G.V$ est représenté par une élément du tableau $G.Adj$
\item $G.Adj[u]$ est la liste d'adjacence de $u$, c'est-à-dire la
  liste des sommets $v$ tels que $(u,v)\in E$
\end{itemize}
\end{itemize}

\bigskip

Permet de représenter des graphes dirigés ou non
\begin{itemize}
\item Si le graphe est dirigé (resp. non dirigé), la somme des longueurs des listes de $G.Adj$ est 
$|E|$ (resp. $2|E|$).
\end{itemize}

\bigskip

Permet de représenter un graphe pondéré en associant un poids à chaque
élément de liste

\end{frame}

\begin{frame}{Exemple}

Graphe non dirigé
\centerline{\includegraphics[width=8cm]{Figures/07-adjgraphundirected.pdf}}

\bigskip

Graphe dirigé
\centerline{\includegraphics[width=8cm]{Figures/07-adjgraphdirected.pdf}}

\end{frame}

\begin{frame}{Complexités}
\begin{itemize}
\item Complexité en espace: \uncover<2->{$O(|V|+|E|)$
\begin{itemize}
\item optimal
\end{itemize}}
\item Accéder à un sommet: \uncover<3->{$O(1)$
\begin{itemize}
\item optimal
\end{itemize}}
\item Parcourir tous les sommets: \uncover<4->{$\Theta(|V|)$
\begin{itemize}
\item optimal
\end{itemize}}
\item Parcourir toutes les arêtes: \uncover<5->{$\Theta(|V|+|E|)$
\begin{itemize}
\item ok (mais pas optimal)
\end{itemize}}
\item Vérifier l'existence d'une arête $(u,v)\in E$: \uncover<6->{$O(|V|)$
\begin{itemize}
\item ou encore $O(min(degree(u),degree(v)))$
\item mauvais
\end{itemize}}
\end{itemize}

{\it (Exercice: insertion, suppression de n\oe uds et d'arêtes ?)}

\note{Discuter des opérations d'insertion et de deletion de n\oe uds et d'arêtes}
\end{frame}

\begin{frame}{Réprésentation II: matrice d'adjacence}
\begin{itemize}
\item Les n\oe uds sont les entiers de 1 à $|V|$, $G.V=\{1,2,\ldots,|V|\}$
\item $G$ est décrit par une matrice $G.A$ de dimension $|V|\times |V|$ 
\item $G.A=(a_{ij})$ tel que
\[
a_{ij}=\left\{\begin{array}{ll}
1 & \mbox{si }(i,j)\in E\\
0 & \mbox{sinon}\\
\end{array}\right.
\]
\bigskip

\item Permet de représenter des graphes dirigés ou non
\begin{itemize}
\item $G.A$ est symmétrique si le graphe est non dirigé
\end{itemize}
\item Graphe pondéré: $a_{ij}$ est le poids de l'arête $(i,j)$ si elle existe, NIL (ou 0, ou $+\infty$) sinon
\end{itemize}
\end{frame}

\begin{frame}{Exemple}

Graphe non dirigé
\centerline{\includegraphics[width=8cm]{Figures/07-matgraphundirected.pdf}}

\bigskip

Graphe dirigé
\centerline{\includegraphics[width=8cm]{Figures/07-matgraphdirected.pdf}}

\end{frame}

\begin{frame}{Complexités}
\begin{itemize}
\item Complexité en espace: \uncover<2->{$O(|V|^2)$
\begin{itemize}
\item potentiellement très mauvais
\end{itemize}}
\item Accéder à un sommet: \uncover<3->{$O(1)$
\begin{itemize}
\item optimal
\end{itemize}}
\item Parcourir tous les sommets: \uncover<4->{$\Theta(|V|)$
\begin{itemize}
\item optimal
\end{itemize}}
\item Parcourir toutes les arêtes: \uncover<5->{$\Theta(|V|^2)$
\begin{itemize}
\item potentiellement très mauvais
\end{itemize}}
\item Vérifier l'existence d'une arête $(u,v)\in E$: \uncover<6->{$O(1)$
\begin{itemize}
\item optimal
\end{itemize}}
\end{itemize}
{\it (Exercice: insertion, suppression de n\oe uds et d'arêtes ?)}
\end{frame}

\begin{frame}{Représentations}
\begin{itemize}
\item Listes d'adjacence:
\begin{itemize}
\item Complexité en espace optimal
\item Pas appropriée pour des graphes \alert{denses\footnote{$|E|\approx |V|^2$}} et des algorithmes qui ont besoin d'accéder aux arêtes
\item Préférable pour des graphes \alert{creux\footnote{$|E|\ll |V|^2$}} ou de degré faible
\end{itemize}

\bigskip

\item Matrice d'adjacence:
\begin{itemize}
\item Complexité en espace très mauvaise pour des graphes creux
\item Appropriée pour des algorithmes qui désirent accéder aléatoirement aux arêtes
\item Préférable pour des graphes \alert{denses}
\end{itemize}
\end{itemize}

\end{frame}

\section{Parcours de graphes}

\begin{frame}{Plan}

\tableofcontents[currentsection]

\end{frame}

\begin{frame}{Parcours de graphes}
\begin{itemize}
\item Objectif: parcourir tous les sommets d'un graphe qui sont
  accessibles à partir d'un sommet $v$ donné
\item Un sommet $v'$ est accessible à partir de $v$ si:
\begin{itemize}
\item soit $v'=v$,
\item soit $v'$ est adjacent à $v$,
\item soit $v'$ est adjacent à un sommet $v''$ qui est accessible à partir de $v$
\end{itemize}

\bigskip

\item Différents types de parcours:
\begin{itemize}
\item En profondeur d'abord ({\it depth-first})
\item En largeur d'abord ({\it breadth-first})
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Parcours en largeur d'abord ({\it breadth-first search})}
\begin{itemize}
\item Un des algorithmes les plus simples pour parcourir un graphe
\item A la base de plusieurs algorithmes de graphe importants%(Dijkstra, Prim...)

\bigskip

\item Entrées: un graphe $G=(V,E)$ et un sommet $s\in V$
\begin{itemize}
\item Parcourt le graphe en visitant tous les sommets qui sont accessibles à partir de $s$
\item Parcourt les sommets par ordre croissant de leur distance (en
  nombre minimum d'arêtes) par rapport à $s$
\begin{itemize}
\item on visite $s$
\item tous les voisins de $s$
\item tous les voisins des voisins de $s$
\item etc.
\end{itemize}
%\item Calcule pour chaque sommet $v\in V$ sa distance $v.d$ à $s$
%\item Produit un arbre {\it en profondeur d'abord} ayant pour racine $s$
\item Fonctionne aussi bien pour des graphes dirigés que non dirigés
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Exemple}

\centerline{\includegraphics[width=8cm]{Figures/07-breadth-first-graph.pdf}}
Un parcours en largeur à partir de $s$: $s$-$a$-$c$-$e$-$g$-$b$-$h$-$i$-$f$

\bigskip

Pour l'implémentation:
\begin{itemize}
\item On doit retenir les sommets déjà visités de manière à éviter de
  boucler infiniment
\item On doit retenir les sommets visités dont on n'a pas encore
  visité les voisins
\end{itemize}

\end{frame}

\begin{frame}{Parcours en largeur d'abord: implémentation}

\begin{columns}
\begin{column}{6cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{BFS}(G,s)$}
        \li \For each vertex $u \in G.V\setminus \{s\}$
        \li \Do $u.d=\infty$\End
        \li $s.d=0$
        \li $Q=$"create empty Queue"
        \li $\proc{Enqueue}(Q,s)$
        \li \While not $\proc{Queue-Empty}(Q)$
        \li \Do $u=\proc{Dequeue}(Q)$
        \li \For each $v\in G.Adj[u]$
        \li\Do \If $v.d=\infty$
        \li \Then $v.d=u.d+1$
        \li $\proc{Enqueue}(Q,v)$\End\End\End
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{6cm}
\begin{itemize}
\item $v.d$ est la distance de $v$ à $s$
\begin{itemize}
\item si un sommet $v$ a été visité, $v.d$ est fini
\item on peut remplacer $d$ par un drapeau binaire
\end{itemize}

\bigskip

\item $Q$ est une file (LIFO) qui contient les sommets visités mais
  dont les voisins n'ont pas encore été visités
\end{itemize}
\end{column}
\end{columns}

\end{frame}


\begin{frame}{Parcours en largeur d'abord: complexité}

\begin{columns}
\begin{column}{6cm}
\begin{center}
{\small\vspace{-0.3cm}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{BFS}(G,s)$}
        \li \For each vertex $u \in G.V\setminus \{s\}$
        \li \Do $u.d=\infty$\End
        \li $s.d=0$
        \li $Q=\emptyset$
        \li $\proc{Enqueue}(Q,s)$
        \li \While $Q\neq \emptyset$
        \li \Do $u=\proc{Dequeue}(Q)$
        \li \For each $v\in G.Adj[u]$
        \li\Do \If $v.d=\infty$
        \li \Then $v.d=u.d+1$
        \li $\proc{Enqueue}(Q,v)$\End\End\End
        %% \Procname{$\proc{BFS}(G,s)$}
        %% \li \For each vertex $u \in G.V\setminus \{s\}$
        %% \li \Do $u.color=\const{White}$
        %% \li $u.d=\infty$
        %% \li $u.\pi=\const{NIL}$\End
        %% \li $s.color=\const{Gray}$
        %% \li $s.d=0$
        %% \li $s.\pi=\const{NIL}$
        %% \li $Q=\emptyset$
        %% \li $\proc{Enqueue}(Q,s)$
        %% \li \While $Q\neq \emptyset$
        %% \li \Do $u=\proc{Dequeue}(Q)$
        %% \li \For each $v\in G.Adj[u]$
        %% \li\Do \If $v.color\isequal \const{White}$
        %% \li \Then $v.color=\const{Gray}$
        %% \li $v.d=u.d+1$
        %% \li $v.\pi = u$
        %% \li $\proc{Enqueue}(Q,v)$\End\End
        %% \li $u.color=\const{Black}$\End
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5cm}
\begin{itemize}
\item Chaque sommet est enfilé au plus une fois
  ($v.d$ infini $\rightarrow v.d$ fini)
\item Boucle $\While$ exécutée $O(|V|)$ fois
\item Boucle interne: $O(|E|)$ \alert{au total}
\item Au total: $O(|V|+|E|)$
\end{itemize}
\end{column}
\end{columns}

\end{frame}

\begin{frame}{Parcours en largeur d'abord}

\begin{itemize}
\item Correction:
\begin{itemize}
\item L'algorithme fait bien un parcours du graphe en largeur et $v.d$ contient bien la distance minimale de $s$ à $v$
\item Ok intuitivement mais pas évident à montrer formellement. On le
  fera plus loin pour l'algorithme de Dijkstra (calcul du plus court
  chemin)
\end{itemize}

\bigskip

\item Applications:
\begin{itemize}
\item Calcul des plus courtes distances d'un sommet à tous les autres
\item Recherche du plus court chemin entre deux sommets
\item Calcul du diamètre d'un arbre
\item Tester si un graphe est biparti
\item \ldots
\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{Parcours en profondeur d'abord}

\begin{itemize}
\item Parcours du graphe en profondeur:
\begin{itemize}
\item On suit immédiatement les arêtes incidentes au dernier sommet visité
\begin{itemize}
\item Au lieu de les mettre en attente dans une file
\end{itemize}
\item On revient en arrière ({\it backtrack}) quand le sommet visité
  n'a plus de sommets adjacents non visités
\end{itemize}

\bigskip

\item Exemple:
\centerline{\includegraphics[width=10cm]{Figures/07-dfs-exemple-onenode.pdf}}

\bigskip

Parcours en profondeur à partir de $A$: $A$-$D$-$F$-$G$-$B$-$E$ ($C$ et $H$ pas accessibles)
\end{itemize}

%% \item Entrée: un graphe $G=(V,E)$ (pas de sommet source !)
%% \item Sortie: 2 ``dates'' associées à chaque sommet $v$:
%% \begin{itemize}
%% \item $v.d$=début du traitement du sommet $v$ (découverte du sommet)
%% \item $v.f$=fin du traitement du sommet $v$
%% \end{itemize}
%% \end{itemize}

\note{On ne voit pas un algo qui parcourt le graphe comme le
  bread-first parce que l'algo ici sera utile pour d'autres
  applications. Notamment le tri topologique}
\end{frame}

%% \begin{frame}{Exemple}

%% \centerline{\includegraphics[width=10cm]{Figures/07-dfs-exemple-onenode.pdf}}

%% \bigskip

%% Parcours en profondeur à partir de $A$: $A$-$D$-$F$-$G$-$B$-$E$ ($C$ et $H$ pas accessibles)

%% \end{frame}

\begin{frame}{Parcours en profondeur: implémentation avec une pile}

\begin{columns}
\begin{column}{5.5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS}(G,s)$}
        \li \For each vertex $u \in G.V$
        \li \Do $u.visited=\const{False}$\End
        \li $S=$"create empty stack"
        \li $\proc{Push}(S,s)$
        \li \While not $\proc{Stack-empty}(S)$
        \li \Do $u=\proc{Pop}(S)$
        \li \If $u.visited\isequal \const{False}$
        \li \Then $u.visited=\const{True}$        
        \li \For each $v\in G.Adj[u]$
        \li\Do \If $v.visited\isequal\const{False}$
        \li \Then $\proc{Push}(S,v)$\End\End\End\End
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{4.5cm}
\begin{itemize}
\item On remplace la file $Q$ par une pile $S$
\item L'attribut $visited$ marque les sommets visités

\bigskip

\item Chaque sommet est empilé au plus une fois
\item Boucle $\While$ executées $O(|V|)$ fois
\item Boucle interne: $O(|E|)$ \alert{au total}
\item Complexité: $O(|V|+|E|)$
\end{itemize}
\end{column}
\end{columns}

\note{Faire tourner l'algorithme sur l'exemple précédent

\bigskip

Au plus une fois: au premier appel sur un sommet, visited est mis à
true et il n'y a plus d'autre appel sur un sommet dont visited est à true

\bigskip

Au lieu de visisted, on pourrait stocker les sommets dans une table hash}

\end{frame}

\begin{frame}{Parcours en profondeur: implémentation récursive}

\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS}(G,s)$}
        \li \For each vertex $u \in G.V$
        \li \Do $u.visited=\const{False}$\End
        \li $\proc{DFS-rec}(G,s)$
      \end{codebox}}

\bigskip

\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS-Rec}(G,s)$}
        \li $s.visited=\const{True}$
        \li \For each $v\in G.Adj[s]$
        \li \Do \If $v.visited\isequal\const{False}$
        \li \Then $\proc{DFS-Rec}(G,v)$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5.5cm}
\begin{itemize}
\item Remplace la pile par la récursion
\bigskip
\item $\proc{DFS-REC}$ appelée au plus $|V|$ fois
\item Chaque arête est considérée au plus une fois dans la boucle $\For$
\item Complexité: $O(|V|+|E|)$
\end{itemize}
\end{column}
\end{columns}

\note{Faire tourner l'algorithme sur l'exemple précédent}

\end{frame}

\begin{frame}{Parcourir tous les sommets d'un graphe}

\begin{itemize}
\item $\proc{BFS}$ et $\proc{DFS}$ ne visitent que les n\oe uds
  accessibles à partir de la source $s$
\begin{itemize}
\item Graphe non dirigé: seule la composante connexe contenant $s$ est visitée
\item Graphe dirigé: certains sommets peuvent ne pas être accessibles
  de $s$ en suivant le sens des arêtes
\end{itemize}
\item Pour parcourir tous les sommets d'un graphe:
\begin{enumerate}
\item On choisit un sommet arbitraire $v$
\item On visite tous les sommets accessibles depuis $v$ (en profondeur ou en largeur)
\item S'il reste certains sommets non visités, on en choisit un et on retourne en (2)
\end{enumerate}
\end{itemize}

\end{frame}

\begin{frame}{Parcours en profondeur de tous les sommets}

\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS-all}(G)$}
        \li \For each vertex $u \in G.V$
        \li \Do $u.visited=\const{False}$\End
        \li \For each vertex $u \in G.V$
        \li \Do \If $u.visited\isequal \const{False}$
        \li \Then $\proc{DFS-Rec}(G,u)$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS-Rec}(G,s)$}
        \li $s.visited=\const{True}$
        \li \For each $v\in G.Adj[s]$
        \li \Do \If $v.visited\isequal\const{False}$
        \li \Then $\proc{DFS-Rec}(G,v)$
      \end{codebox}}
}
\end{center}
\end{column}
\end{columns}

\bigskip

\begin{itemize}
\item Complexité: $\Theta(|V|+|E|)$
\begin{itemize}
\item $\proc{DFS-Rec}$ est appelé sur chaque sommet une et une seule fois
$$\Theta(|V|)$$
\item La boucle $\For$ de $\proc{DFS-Rec}$ parcourt chaque liste
  d'adjacence une et une seule fois $$\Theta(\sum_{u\in G.V} outdegree(u))=\Theta(|E|)$$
\end{itemize}
\end{itemize}

\note{Au moins une fois, par la boucle dans $\proc{DFS-All}$. Au plus
  une fois car $visited$ est mis à true la première fois}

\end{frame}

\begin{frame}{Sous-graphe de liaison}

Un parcours en profondeur de tous les sommets d'un graphe construit un
ensemble d'arbres (une \alert{forêt}), appelé sous-graphe de liaison, où:
\begin{itemize}
\item les sommets sont les sommets du graphe,
\item un sommet $w$ est le fils d'un sommet $v$ dans la forêt si
  $\proc{DFS-rec}(G,w)$ est appelé depuis $\proc{DFS-rec}(G,v)$
\end{itemize}

\bigskip

Exemple:

\centerline{\includegraphics[width=9cm]{Figures/07-dfs-forest.pdf}}

\bigskip

{\it (Exercice: modifiez $\proc{DFS-All}$ et $\proc{DFS-Rec}$ pour construire la forêt)}

\note{L'arbre n'est pas unique !!

\bigskip

Que se passe-t'il si on applique ça à un graphe non orienté ? Combien y aura-t'il d'arbres ?
}
\end{frame}

%% \begin{frame}{Parcours en profondeur d'abord: complexité}

%% \begin{columns}
%% \begin{column}{5cm}
%% \begin{center}
%% {\small
%% \fcolorbox{white}{Lightgray}{%
%%       \begin{codebox}
%%         \Procname{$\proc{DFS}(G)$}
%%         \li \For each vertex $u \in G.V$
%%         \li \Do $u.color=\const{White}$\End
%%         \li $time=0$ \Comment global variable
%%         \li \For each $u\in G.V$
%%         \li  \Do \If $u.color\isequal \const{White}$
%%         \li   \Then $\proc{DFS-Visit}(G,u)$\End\End
%%       \end{codebox}}
%% }
%% \end{center}
%% \end{column}
%% \begin{column}{5cm}
%% \begin{center}
%% {\small
%% \fcolorbox{white}{Lightgray}{%
%%       \begin{codebox}
%%         \Procname{$\proc{DFS-Visit}(G,u)$}
%%         \li $time=time+1$
%%         \li $u.d=time$
%%         \li $u.color=\const{Gray}$
%%         \li \For each $v\in G.Adj[u]$
%%         \li \Do \If $v.color\isequal \const{White}$
%%         \li \Then $\proc{DFS-Visit}(G,v)$\End\End
%%         \li $u.color=\const{Black}$
%%         \li $time = time + 1$
%%         \li $u.f=time$
%%       \end{codebox}}
%% }
%% \end{center}
%% \end{column}
%% \end{columns}

%% \bigskip

%% \begin{itemize}
%% \item Boucle lignes 4-6 de $\proc{DFS-Visit}(G,u)$: $\Theta(out-degree(u))$
%% \item $\proc{DFS-Visit}(G,u)$ est appelé une seule fois pour chaque sommet
%% \begin{itemize}
%% \item On l'appelle sur un sommet blanc uniquement et on le marque gris directement après l'appel
%% \end{itemize}
%% \item Complexité globale: $\Theta(|V|+|E|)$
%% \end{itemize}

%% \note{Pourquoi $\Theta$ ? Parce que l'algorithme parcourt tout le graphe contrairement au breadth-first}

%% \end{frame}

\begin{frame}{Application: tri topologique}
\begin{itemize}
\item Tri topologique:
\begin{itemize}
\item Etant donné un \alert{graphe acyclique dirigé} (DAG), trouver un
  ordre des sommets tel qu'il n'y ait pas d'arête d'un n\oe ud vers un
  des n\oe uds qui le précède dans l'ordre
\item On peut montrer que c'est possible si (et seulement si) le
  graphe est acyclique
\end{itemize}

\bigskip

\item Exemples d'applications:
\begin{itemize}
\item Trouver un ordre pour suivre un ensemble de cours qui tienne compte des prérequis de chaque cours
\begin{itemize}
\item Pour suivre SDA, il faut avoir suivi Introduction à la programmation
\end{itemize}
\item Résoudre les dépendances pour l'installation de logiciels
\begin{itemize}
\item Trouver un ordre d'installation de manière à ce que chaque logiciel soit installé après tous ceux dont il dépend
\end{itemize}
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Illustration}
Graphe

\centerline{\includegraphics[width=8cm]{Figures/07-tritopo-exemple.pdf}}

\bigskip

Une tri topologique

\centerline{\includegraphics[width=10cm]{Figures/07-tritopo-exemple-solution.pdf}}

\end{frame}

\begin{frame}{Marquage des sommets pour le parcours en profondeur}

\begin{itemize}
\item Dans le cadre d'un parcours en profondeur de tous les sommets,
  $\proc{DFS-rec}$ est appelé une et une seule fois sur chaque sommet
\item Lors de l'exécution de $\proc{DFS-All}$, on dira qu'un sommet
  $v$ est \alert{fini} si l'appel $\proc{DFS-rec}(G,v)$ est terminé
\item A un moment donné, les sommets peuvent être dans les trois états suivants:
\begin{itemize}
\item pas encore visité (on dira que $v$ est \alert{blanc})
\item visité mais pas encore fini ($v$ est \alert{gris})
\item fini ($v$ est \alert{noir})
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Marquage des sommets pour le parcours en profondeur}

\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS-all}(G)$}
        \li \For each vertex $u \in G.V$
        \li \Do $u.color=\const{White}$\End
        \li \For each vertex $u \in G.V$
        \li \Do \If $u.color\isequal \const{White}$
        \li \Then $\proc{DFS-Rec}(G,u)$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DFS-Rec}(G,s)$}
        \li $s.color=\const{Gray}$
        \li \For each $v\in G.Adj[s]$
        \li \Do \If $s.color\isequal\const{White}$
        \li \Then $\proc{DFS-Rec}(G,v)$\End\End
        \li $s.color=\const{Black}$
      \end{codebox}}
}
\end{center}
\end{column}
\end{columns}

\bigskip

\bigskip

\begin{itemize}
\item \alert{Lemme.} Soit $s$ un sommet de $G$. Considérons le moment
  de l'exécution de $\proc{DFS-All}(G)$ où $\proc{DFS-Rec}(G,s)$ est
  appelé. Pour tout sommet $v$, on a:
\begin{enumerate}
\item Si $v$ est blanc et accessible depuis $s$, alors $v$ sera noir avant $s$
\item Si $v$ est gris, alors $s$ est accessible depuis $v$
\end{enumerate}
\end{itemize}

\note{Propriété 2: si $v$ est gris, ça veut dire qu'on est dans la
  partie 2-4 de DFS-Rec et donc qu'on a atteint $s$ en parcourant le
  graphe depuis $s$ en profondeur. Donc, $s$ est accessible depuis $v$.}

\end{frame}

\begin{frame}{Trouver un tri topologique par DFS}
\begin{itemize}
\item Soit un graphe $G=(V,E)$ et l'ordre suivant défini sur $V$:
$$s\prec v\Leftrightarrow v\mbox{ devient noir avant }s$$
\item Si $G$ est un DAG, alors $\prec$ définit un ordre topologique sur $G$

\bigskip

\item \alert{Preuve:}
\begin{itemize}
\item Soit $(s,v)\in E$. On doit montrer que $s\prec v$.
\item Considérons le moment où $\proc{DFS-rec}(G,s)$ est appelé:
\begin{itemize}
\item Si $v$ est déjà noir, alors $s\prec v$ par définition de $\prec$
\item Si $v$ est blanc, alors $v$ sera noir avant $s$ par le lemme
  précédent. Donc $s\prec v$
\item Si $v$ est gris, $s$ est accessible depuis $v$ et donc il y a un
  cycle (puisque $(s,v)\in E$). Ce qui ne peut pas arriver vu que $G$ est un DAG
\end{itemize}\qed
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Tri topologique: implémentation}

\begin{columns}
\begin{column}{5.5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Top-Sort}(G)$}
        \li \For each vertex $u \in G.V$
        \li \Do $u.color=\const{White}$\End
        \li $L=$"create empty linked list"
        \li \For each vertex $u \in G.V$
        \li \Do \If $u.color\isequal \const{White}$
        \li \Then $\proc{Top-Sort-Rec}(G,u,L)$\End\End
        \li \Return $L$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5.5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Top-Sort-Rec}(G,s,L)$}
        \li $s.color=\const{Gray}$
        \li \For each $v\in G.Adj[s]$
        \li \Do \If $s.color\isequal\const{White}$
        \li \Then $\proc{Top-Sort-Rec}(G,v,L)$
        \li \ElseIf $s.color\isequal\const{Grey}$
        \li \Then $\proc{Error}$ "$G$ has a cycle"\End\End        
        \li $s.color=\const{Black}$
        \li $\proc{Insert-First}(L,s)$
      \end{codebox}}
}
\end{center}
\end{column}
\end{columns}

\bigskip

Complexité: $\Theta(|V|+|E|)$

\end{frame}

\begin{frame}{Illustration}

Graphe

\centerline{\includegraphics[width=8cm]{Figures/07-tritopo-exemple.pdf}}

\bigskip

Une tri topologique

\centerline{\includegraphics[width=10cm]{Figures/07-tritopo-exemple-solution.pdf}}

\note{Est-ce que vous avez une autre idée, basée sur une approche gloutonne ?}

\end{frame}

\begin{frame}{Une autre solution}

\begin{itemize}
\item Approche gloutonne:
\begin{itemize}
\item Rechercher un sommet qui n'a pas d'arête entrante
\begin{itemize}
\item C'est toujours possible dans un graphe acyclique
\end{itemize}
\item Ajouter ce sommet à un tri topologique du graphe dont on a retiré ce sommet et toutes ses arêtes
\begin{itemize}
\item Ce graphe reste acyclique
\end{itemize}
\end{itemize}
\item Complexité identique à l'approche DFS: $\Theta(|E|+|V|)$
\end{itemize}

\end{frame}


\section{Plus courts chemins}

\begin{frame}{Plan}

\tableofcontents[currentsection]

\end{frame}

% definition du probleme + propriétés (cycles négatifs, etc.)

\begin{frame}{Définitions}

\begin{itemize}
\item Soit un graphe dirigé $G=(V,E)$ et une fonction de poids $w:
  E\rightarrow I\!R$
\item Un chemin (du sommet $v_1$ au sommet $v_k$) est une séquence de
  n\oe uds $v_1, v_2,\ldots, v_k$ telle que $\forall i=1,\ldots,k-1$,
  $(v_i,v_{i+1})\in E$.
\item Le poids (ou coût) d'un chemin $p$ est la somme du poids des arêtes qui le composent:
$$w(p)=w(v_1,v_2)+w(v_2,v_3)+\ldots+w(v_{k-1},v_k)$$
\item Exemple
\centerline{\includegraphics[width=4cm]{Figures/07-poidschemin.pdf}}
$$w(s\rightarrow y \rightarrow t\rightarrow x\rightarrow z)=5+1+6+2=14$$
\end{itemize}

\end{frame}

\begin{frame}{Plus courts chemins: définition}

\begin{itemize}
\item Un \alert{plus court chemin} entre deux sommets $u$ et $v$ est un chemin
  $p$ de $u$ à $v$ de poids $w(p)$ le plus faible possible
\item $\delta(u,v)$ est le poids d'un plus court chemin de $u$ à $v$:
$$\delta(u,v)=\min\{w(p)|p \mbox{ est un chemin de }u\mbox{ à }v\}$$
(S'il n'y a pas de chemin entre $u$ et $v$, $\delta(u,v)=\infty$ par définition)
\item Exemples:

\bigskip

\centerline{\includegraphics[width=9cm]{Figures/07-pcc-exemples.pdf}}

%{\small(Chaque n\oe ud $v$ est marqué de la valeur de $\delta(0,v)$)}

\end{itemize}

\note{Plusieurs plus court chemin}

\end{frame}

\begin{frame}{Plus courts chemins: exemple d'application}

\centerline{\includegraphics[width=9cm]{Figures/07-pcc-montef-1.pdf}}

\end{frame}

\begin{frame}{Propriété de sous-structure optimale}

\begin{itemize}
\item \alert{Lemme:} Tout sous-chemin d'un chemin le plus court est un chemin le plus court entre ses extrémités

\bigskip

\item \alert{Preuve:} Par l'absurde
\begin{itemize}
\item Soit un plus court chemin $p_{uv}$ entre $u$ et $v$ et soit un sous-chemin $p_{xy}$ de ce chemin défini par ses extrémités $x$ et $y$
\item S'il existe un chemin plus court que $p_{xy}$ entre $x$ et $y$, on pourrait remplacer $p_{xy}$ par ce chemin dans le chemin entre $u$ et $v$ et obtenir ainsi un chemin plus court que $p_{uv}$ entre $u$ et $v$
\end{itemize}\qed
\end{itemize}

\bigskip

\centerline{\includegraphics[width=7cm]{Figures/07-pcc-sousstructure.pdf}}

\end{frame}

\begin{frame}{Poids négatifs}

\begin{itemize}
\item Les poids peuvent être négatifs
\item Ok la plupart du temps mais non permis par certains algorithmes (Dijkstra)
\item Problème en cas de cycle de poids négatif (\alert{cycle absorbant}):
\begin{itemize}
\item En restant dans le cycle négatif, on peut diminuer arbitrairement le poids du chemin
\item Par définition, on fixera $\delta(u,v)=-\infty$ s'il y a un chemin de $u$ à $v$ qui passe par un cycle négatif
\end{itemize}
\end{itemize}

\centerline{\includegraphics[width=5.5cm]{Figures/07-pcc-negative.pdf}}

$$\delta(s,e)=\delta(s,f)=\delta(s,g)=-\infty$$

\end{frame}

\begin{frame}{Cycles}

Un chemin le plus court ne peut pas contenir de cycles
\begin{itemize}
\item Cycles de poids négatifs: on les a déjà exclus par définition
\item Cycles de poids positifs: on peut obtenir un chemin plus court en les supprimant
\item Cycles de poids nuls: il n'y a pas de raison de les utiliser et donc, on ne le fera pas
\end{itemize}

\end{frame}

\begin{frame}{Plus courts chemins: variantes de problèmes}

Différentes variantes du problème:
\begin{itemize}
\item \alert{Origine unique}: trouver tous les plus courts chemins d'un sommet à tous les autres
\begin{itemize}
\item Algorithmes de Dijkstra et Bellman-Ford
\end{itemize}
\item \alert{Destination unique}: trouver tous les plus courts chemins de tous les sommets vers un sommet donné
\begin{itemize}
\item Essentiellement le même problème que l'origine unique
\end{itemize}
\item \alert{Paire unique}: trouver un plus court chemin entre deux sommets donnés.
\begin{itemize}
\item Pas de meilleure solution que de résoudre le problème ``origine unique''.
\end{itemize}
\item \alert{Toutes les paires}: trouver tous les plus courts chemin de $u$ à
  $v$ pour toutes les paires de sommets $(u,v)\in V\times V$.
\begin{itemize}
\item Algorithme de Floyd-Warshall
\end{itemize}
\end{itemize}

\note{On va donc se focaliser sur origine unique et toutes les paires}
\end{frame}

% Principe des algorithmes


\begin{frame}{Recherche du plus court chemin, origine unique}

\begin{itemize}
\item Entrées: un graphe dirigé pondéré et un sommet $s$ (l'origine)
\item Sorties: deux attributs pour chaque sommet:
\begin{itemize}
\item $v.d=\delta(s,v)$, la plus courte distance de $s$ vers chaque n\oe ud
\item $v.\pi=$ le prédécesseur de chaque sommet $v$ dans un plus court chemin de $s$ à $v$\\
(formant \alert{l'arbre} des plus courts chemins partant de $s$)
\end{itemize}
\end{itemize}

\centerline{\includegraphics[width=5cm]{Figures/07-pcc-sssp.pdf}}

\centerline{\small(Chaque n\oe ud $v$ est marqué de la valeur de $\delta(0,v)$)}

\end{frame}

\begin{frame}{Approche force brute}

\begin{itemize}
\item Calculer le poids de tous les chemins entre deux n\oe uds et renvoyer le plus court
\item Problème:
\begin{itemize}
\item Le nombre de chemins peut être infini (dans le cas de cycles)

\item Le nombre de chemins peut être exponentiel par rapport au nombre de sommets et d'arêtes\\

\bigskip

\centerline{\includegraphics[width=8cm]{Figures/07-exponentielnbnodes.pdf}}

\bigskip

\centerline{($O(n)$ n\oe uds et $2^n$ chemins entre $s$ et $v_n$)}

\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Schéma général d'un algorithme}

\begin{itemize}
\item Objectif: calculer $v.d=\delta(s,v)$ pour tout $v\in V$

\bigskip

\item Idée d'algorithme:
\begin{itemize}
\item $v.d$ à un itération donnée contient une \alert{estimation} du poids d'un plus court chemin de $s$ à $v$
\item Invariant: $v.d\geq \delta(s,v)$
\item Initialisation: $v.d=+\infty$ ($\forall v \in V$)
\item A chaque itération, on tente d'améliorer (c'est-à-dire diminuer) $v.d$ en maintenant l'invariant
\item A la convergence, on aura $v.d=\delta(s,v)$
\item L'amélioration est basée sur l'utilisation de l'inégalité triangulaire
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Inégalité triangulaire et relâchement}
\begin{itemize}
\item \alert{Théorème:} Pour tout $u, v, x \in V$, on a
$$\delta(u,v)\leq \delta(u,x)+\delta(x,v)$$
\item \alert{Preuve:} Aller de $u$ à $v$ en empruntant un plus court chemin passant par $x$ ne peut pas être plus court qu'un plus court chemin de $u$ à $v$.

\bigskip

\item \alert{Corrolaire:} Pour tout $(u,v)\in E$, on a $$\delta(s,v)\leq \delta(s,u)+w(u,v)$$

\bigskip

\item Amélioration d'une arête (\alert{Relâchement}):
\end{itemize}

\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Relax}(u,v,w)$}
        \li \If $v.d>u.d+w(u,v)$
        \li \Then $v.d=u.d+w(u,v)$
      \end{codebox}
}}
\end{center}
\end{column}
\begin{column}{5cm}
\centerline{\includegraphics[width=5cm]{Figures/07-pcc-relaxation.pdf}}
\end{column}
\end{columns}

\end{frame}

\begin{frame}{Schéma général d'un algorithme}

\begin{columns}
\begin{column}{5cm}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Single-source-SP}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \While $\exists (u,v): v.d> u.d+w(u,v)$
        \li \Do Pick one edge (u,v)
        \li $\proc{Relax}(u,v,w)$\End
      \end{codebox}
}}
\end{column}
\begin{column}{5cm}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Init-single-source}(G,s)$}
        \li \For each $v \in G.V$
        \li \Do $v.d=\infty$\End
        \li $s.d=0$
      \end{codebox}
}}
\end{center}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Relax}(u,v,w)$}
        \li \If $v.d>u.d+w(u,v)$
        \li \Then $v.d=u.d+w(u,v)$
      \end{codebox}
}}
\end{center}
\end{column}
\end{columns}

\begin{itemize}
\item On obtient différents algorithmes en modifiant la manière dont on sélectionne les arêtes
\end{itemize}

\end{frame}

\begin{frame}{Schéma général d'un algorithme}


\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Single-source-SP}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \While $\exists (u,v): v.d\geq u.d+w(u,v)$
        \li \Do Pick one edge (u,v)
        \li $\proc{Relax}(u,v,w)$\End
      \end{codebox}
}}
\end{center}
\end{column}
\begin{column}{5cm}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Init-single-source}(G,s)$}
        \li \For each $v \in G.V$
        \li \Do $v.d=\infty$
        \li  {\color{red}$v.\pi=\const{NIL}$} \End
        \li $s.d=0$
      \end{codebox}
}}
\end{center}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Relax}(u,v,w)$}
        \li \If $v.d>u.d+w(u,v)$
        \li \Then $v.d=u.d+w(u,v)$
        \li {\color{red} $v.\pi=u$}\End
      \end{codebox}
}}
\end{center}
\end{column}
\end{columns}

\begin{itemize}
\item En ajoutant la construction de l'arbre des plus courts chemins
\end{itemize}

\end{frame}

\begin{frame}{Propriétés de l'algorithme général}

\begin{itemize}
\item \alert{Propriété 1:} L'algorithme général maintient toujours l'invariant

\bigskip

\item \alert{Preuve:} Par induction sur le nombre d'itérations
\begin{itemize}
\item Cas de base: l'invariant est vérifié après l'initialisation
\item Cas inductif:
\begin{itemize}
\item Soit un appel à $relax(u,v,w)$
\item Avant l'appel, on suppose que l'invariant est vérifié et donc $u.d\geq \delta(s,u)$
\item Par l'inégalité triangulaire:
\begin{eqnarray*}
\delta(s,v) &\leq& \delta(s,u)+\delta(u,v)\\
&\leq& u.d+w(u,v)
\end{eqnarray*}
\item Suite à l'assignation $v.d=u.d+w(u,v)$, on a bien $$v.d\geq \delta(s,v)$$
\end{itemize}
\end{itemize}

\end{itemize}
\end{frame}

\bigskip

\begin{frame}{Propriétés de l'algorithme général}

\begin{itemize}
\item \alert{Propriété 2:} Une fois que $v.d=\delta(s,v)$, il n'est plus modifié
\item \alert{Preuve:} On a toujours $v.d\geq \delta(s,v)$ et un relâchement ne peut que diminuer $v.d$

\bigskip

\bigskip

\item Vu les propriétés 1 et 2, pour montrer qu'un algorithme du plus court chemin est
  correct, on devra montrer que le \alert{choix} des arêtes à relâcher
  mènera bien à $v.d=\delta(s,v)$ pour tout $v$.

\end{itemize}

\end{frame}



% Algorithme de Bellman-Ford

\begin{frame}{Algorithme de Bellman-Ford}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Single-source-SP}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \While $\exists (u,v): v.d\geq u.d+w(u,v)$
        \li \Do Pick one edge (u,v)
        \li $\proc{Relax}(u,v,w)$\End
      \end{codebox}
}}
\end{center}

\bigskip

\begin{itemize}
\item Algorithme basé sur la relâchement
\item Soit les arêtes $e_1,\ldots,e_m$, dans un ordre quelconque.
\item Le relâchement se fait dans cet ordre:
$$\underbrace{\underbrace{e_1,e_2,\ldots,e_m};\underbrace{e_1,e_2,\ldots,e_m};\ldots;\underbrace{e_1,e_2,\ldots,e_m}}_{|V|-1 fois}$$
\end{itemize}

\end{frame}

\begin{frame}{Algorithme de Bellman-Ford}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Bellman-Ford}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \For i=1 \To $|G.V|-1$
        \li \Do \For each edge $(u,v)\in G.E$
        \li \Do $\proc{Relax}(u,v,w)$\End\End
      \end{codebox}
}}
\end{center}

\bigskip

Illustration sur un exemple:

\centerline{\includegraphics[width=5cm]{Figures/07-bellman-ford.pdf}}

\end{frame}


\begin{frame}{Analyse: complexité}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Bellman-Ford}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \For i=1 \To $|G.V|-1$
        \li \Do \For each edge $(u,v)\in G.E$
        \li \Do $\proc{Relax}(u,v,w)$\End\End
      \end{codebox}
}}
\end{center}

\begin{itemize}
\item La boucle principale relâche toutes les arêtes $|V|-1$ fois
\item Complexité: $\Theta(|V|\cdot |E|)$
\begin{itemize}
\item En supposant qu'on puisse parcourir les arêtes en $O(|E|)$
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Analyse: correction}

\begin{itemize}
\item On supposera qu'il n'y a pas de cycle de poids négatif
\item Propriété 3: Après $i$ itérations de l'algorithme, $v.d$ est le
  poids d'un plus court chemin de $s$ à $v$ utilisant au plus $i$ arêtes:
$$v.d\leq \min\{w(p): |p|\leq i\}$$
\item Preuve: Par induction:
\begin{itemize}
\item Cas de base: $v.d=+\infty$ si $i=0$ et $s.d=0$
\item Cas inductif:
\begin{itemize}
\item Avant l'itération $i$, on a $v.d\leq \min\{w(p):|p|\leq i-1\}$
\item Cette propriété reste vraie à tout moment de l'itération puisque
  $\proc{Relax}$ ne peut que diminuer les $v.d$
\item L'itération $i$ considère tous les chemins avec $i$ arêtes ou
  moins en relâchant tous les arêtes entrantes en $v$
\end{itemize}
\end{itemize}
\end{itemize}

\centerline{\includegraphics[width=4cm]{Figures/07-pcc-bellmanford-proof.pdf}}

\note{Pas un égal mais un plus petit ou égal car l'ordre des n\oe uds n'étant pas fixé, on va mixer les updates de path}

\end{frame}

\begin{frame}{Analyse: correction}

\begin{itemize}
\item Si le graphe ne contient pas de cycles de poids négatif, alors,
  à la fin de l'exécution de l'algorithme de Bellman-Ford, on a
  $v.d=\delta(s,v)$ pour tout $v\in V$.

\bigskip

\item Preuve:
\begin{itemize}
\item Sans cycle négatif, tout plus court chemin est \alert{simple}, c'est-à-dire sans cycle
\item Tout chemin simple a au plus $|V|$ sommets et donc $|V|-1$ arêtes
\item Par la propriété 3, on a $v.d\leq \delta(s,v)$ après 
$|V|-1$ itérations
\item Par l'invariant, on a $v.d\geq \delta(s,v)$ $\Rightarrow v.d=\delta(s,v)$
\end{itemize}\qed
\end{itemize}
\end{frame}

\begin{frame}{Détection des cycles négatifs}

\begin{columns}
\begin{column}{4.5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Bellman-Ford}(G,w,s)$}
        \li $\proc{Init-single-source}(G,s)$
        \li \For i=1 \To $|G.V|-1$
        \li \Do \For each edge $(u,v)\in G.E$
        \li \Do $\proc{Relax}(u,v,w)$\End\End
        \li {\color{red}\For each edge $(u,v)\in G.E$}
        \li \Do {\color{red}\If $v.d>u.d+w(u,v)$}
        \li \Then {\color{red}\Return $\const{False}$}\End\End
        \li {\color{red}\Return $\const{true}$}
      \end{codebox}
}}
\end{center}
\end{column}
\begin{column}{5.5cm}
\begin{itemize}
\item Renvoie $\const{True}$ si un cycle négatif (accessible depuis
  $s$) existe, $\const{False}$ sinon
\item En cas de cycle négatif, il existe toujours (et donc aussi en sortie de boucle) au moins un $v.d$ qu'on
  peut améliorer par relâchement d'un arc $(u,v)$
\end{itemize}
\end{column}
\end{columns}

\end{frame}

\begin{frame}{Programmation dynamique}

\begin{itemize}
\item L'algorithme de Bellman-Ford implémente en fait une approche par
  programmation dynamique\footnote{Bellman est en fait l'inventeur de la programmation dynamique}
\item Soit $v.d[i]$, la longueur du plus court chemin de $s$ à $v$ utilisant au plus $i$ arêtes
\item On a
{\footnotesize
\[v.d[i]=\left\{\begin{array}{l}
0 \mbox{   si }v=s\mbox{ et }i=0\\
+\infty \mbox{   si }v\neq s\mbox{ et }i=0\\
\min\{v.d[i-1],\min_{(u,v)\in E}\{u.d[i-1]+w(u,v)\}\} \mbox{   sinon}\\
  \end{array}\right.\]}
\end{itemize}

\bigskip

{\it (Exercice: implémenter l'algorithme de Bellman-Ford à partir de
  la récurrence et comparer le avec la version précédente)}

\note{Différences:
\begin{itemize}
\item Récurrence suggère de parcourir les noeuds et puis pour chaque noeud les arêtes entrantes
\item Bellman-Ford parcourt les arêtes dans n'importe quel ordre (notre preuve montre que l'ordre n'a pas d'importance)
\item Pour la récurrence, on doit stocker un tableau de la taille du nombre de noeud. L'autre implémentation ne nécessite pas cette table !
\end{itemize}
}
\end{frame}

\begin{frame}{Graphe dirigé acyclique (DAG)}

Version plus efficace dans le cas d'un graphe dirigé acyclique:
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{DAG-Shortest-Path}(G,w,s)$}
        \li $L=\proc{Top-Sort}(G)$
        \li $\proc{Init-single-source}(G,s)$
        \li \For each vertex $u$, taken in their order in $L$
        \li \Do \For each vertex $v\in G.Adj[u]$
        \li \Do $\proc{Relax}(u,v,w)$\End\End
      \end{codebox}
}}
\end{center}

\bigskip

Exemple:
\centerline{\includegraphics[width=7cm]{Figures/07-bellmanford-dag.pdf}}

\bigskip

Complexité: $\Theta(|V|+|E|)$

\end{frame}

% Algorithme de Dijkstra

\begin{frame}{Poids unitaires: parcours en largeur d'abord}

\begin{itemize}
\item On peut obtenir une solution plus rapide en imposant certaines
  contraintes sur la nature des poids
\item Si les poids sont tous égaux à 1, le parcours en largeur permet
  de calculer les $v.d$ en $O(|V|+|E|)$
\item Rappel:
\end{itemize}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{BFS}(G,s)$}
        \li \For each vertex $u \in G.V\setminus \{s\}$
        \li \Do $u.d=\infty$\End
        \li $s.d=0$
        \li $Q=$"create empty Queue"
        \li $\proc{Enqueue}(Q,s)$
        \li \While not $\proc{Queue-Empty}(Q)$
        \li \Do $u=\proc{Dequeue}(Q)$
        \li \For each $v\in G.Adj[u]$
        \li\Do \If $v.d=\infty$
        \li \Then $v.d=u.d+1$
        \li $\proc{Enqueue}(Q,v)$\End\End\End
      \end{codebox}}
}
\end{center}

\end{frame}

\begin{frame}{Poids unitaires: parcours en largeur d'abord}

\centerline{\includegraphics[width=8cm]{Figures/07-pcc-bfs.pdf}}

\end{frame}

\begin{frame}{Poids entiers, positifs et bornés}

\begin{itemize}
\item Si les poids sont des entiers compris entre $1\ldots W$:
\begin{itemize}
\item On définit un nouveau graphe en éclatant chaque arête de poids $w$ en $w$ arêtes de poids 1
\item On applique le parcours en largeur sur ce nouveau graphe
\end{itemize}
\item Complexité: $O(|V|+W |E|)$
\end{itemize}

\centerline{\includegraphics[width=7cm]{Figures/07-integerweights.pdf}}

\end{frame}

\begin{frame}{Poids positifs: approche gloutonne}

\begin{itemize}
\item Algorithme de Dijkstra: généralisation du parcours en largeur à
  des poids positifs réels

\bigskip

\item Idée:
\begin{itemize}
\item On maintient un ensemble $S$ de sommets dont le poids d'un plus
  court chemin à partir de $s$ est connu
\item A chaque étape, on ajoute à $S$ un sommet $v\in V\setminus S$ dont la distance à $s$ est minimale
\item On met à jour, par relâchement, les distances estimées des sommets adjacents à $v$
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Algorithme de Dijkstra}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Dijkstra}(G,w,s)$}
        \li $\proc{Init-Single-Source}(G,s)$
        \li $S=\emptyset$
        \li $Q=$"create an empty min priority queue from $G.V$"
        \li \While not $\proc{Empty}(Q)$
        \li \Do $u=\proc{Extract-Min}(Q)$
        \li $S=S\cup \{u\}$
        \li \For each $v\in G.Adj[u]$
        \li\Do $\proc{Relax}(u,v,w)$ {\color{red}\Comment ! $\proc{Relax}$ doit modifier la clé de $v$ dans $Q$}\End\End
      \end{codebox}}
}
\end{center}

\bigskip

Illustration sur un exemple:

\centerline{\includegraphics[width=5cm]{Figures/07-pcc-dijkstra-exemple.pdf}}

\end{frame}


\begin{frame}{Analyse: complexité}

\begin{itemize}
\item Si la file à priorité est implémentée par un tas (min), l'extraction et l'ajustement de la clé sont $O(\log |V|)$
\item Chaque sommet est extrait de la file à priorité une et une seule fois
\begin{itemize}
\item[$\Rightarrow$] $O(|V|\log |V|)$
\end{itemize}
\item Chaque arête est parcourue une et une seule fois et entraîne au plus un ajustement\footnote{Similaire à un $\proc{Heap-Decrease-Key}$} de clé
\begin{itemize}
\item[$\Rightarrow$] $O(|E|\log |V|)$
\end{itemize}
\item Total: $O(|V|\log |V| + |E|\log |V|)=O(|E| \log |V|)$
\begin{itemize}
\item $|E| \log |V|$ domine $|V|\log |V|$ si le graphe est connexe
\end{itemize}
\end{itemize}

\end{frame}

% Calculer tous les chemins: algorithme de Floyd...

\begin{frame}{Analyse: correction}
\begin{itemize}
\item \alert{Théorème}: l'algorithme de Dijkstra se termine avec $v.d=\delta(s,v)$ pour tout $v\in V$
\item \alert{Preuve}:
\begin{itemize}
\item Lorsqu'un n\oe ud $v$ est extrait de la pile, son $v.d$ n'est plus modifié. Il suffit donc de montrer que $v.d=\delta(s,v)$ lorsque $v$ est extrait de $Q$
\item Par l'invariant (propriété 1), on a $v.d\geq \delta(s,v)$ à tout moment
\item Par l'absurde, supposons qu'il existe un n\oe ud $u$ tel que $u.d>\delta(s,u)$ lors de son extraction et soit $u$ le premier n\oe ud satisfaisant cette propriété.
\item Soit $y$ le premier n\oe ud d'un plus court chemin de $s$ à $u$ qui se trouve dans $Q$ avant l'extraction de $u$ et soit $x$ son prédécesseur
\end{itemize}
\end{itemize}

\centerline{\includegraphics[4.5cm]{Figures/07-dijkstra-proof.pdf}}

\note{S'il n'y a pas de y, alors, u est ce y et ce qui suit montre que $y.d=\delta(s,y)$}

\end{frame}

\begin{frame}{Analyse: correction}

\centerline{\includegraphics[4.5cm]{Figures/07-dijkstra-proof.pdf}}

\begin{itemize}
\item[]
\begin{itemize}
\item Puisque $u$ est le premier n\oe ud violant l'invariant, on a $x.d=\delta(s,x)$
\item Par la propriété de sous-structure optimale, le sous-chemin de $s$ à $y$ est un plus court chemin et $y.d$ a été assigné à $x.d+w(x,y)=\delta(s,x)+w(x,y)=\delta(s,y)$ lors de l'extraction de $x$
\item On a donc $y.d=\delta(s,y)\leq \delta(s,u)\leq u.d$
\item Or, $y.d\geq u.d$ puisqu'on s'apprête à extraire $u$ de la file
\item D'où $y.d=\delta(s,y)={\color{red}\delta(s,u)=u.d}$, ce qui contredit notre hypothèse\qed
\end{itemize}
\end{itemize}

\end{frame}


\begin{frame}{Plus court chemin pour toutes les paires de sommets}

Déterminer les plus courts chemins pour toutes les paires de sommets:
\begin{itemize}
\item Entrées: un graphe dirigé $G=(V,E)$, une fonction de poids $w$. Les sommets sont numérotés de 1 à $n$
\item Sortie: une matrice $D=(d_{ij})$ de taille $n\times n$ où $d_{ij}=\delta(i,j)$ pour tous sommets $i$ et $j$
\end{itemize}

\bigskip

\centerline{\includegraphics[width=10cm]{Figures/07-allpairs-exemple.pdf}}

\end{frame}

\begin{frame}{Plus court chemin pour toutes les paires de sommets}

\begin{itemize}
\item Dans le cas général, on peut appliquer Bellman-Ford sur chaque sommet
\begin{itemize}
\item $O(|V|^2 |E|)$, ou $O(V^4)$ si le graphe est dense ($E=\Theta(V^2)$)
\end{itemize}

\bigskip

\item S'il n'y a pas de poids négatifs, on peut appliquer Dijkstra sur chaque sommet
\begin{itemize}
\item $O(|V| |E| \log |V|)$, ou $O(V^3 \log |V|)$ si le graphe est dense
\end{itemize}

\bigskip

\item Il est possible d'obtenir $O(V^3)$ par programmation dynamique
\end{itemize}

\end{frame}

\begin{frame}{Une solution par programmation dynamique}
\begin{itemize}
%\item Soit $V=\{1,\ldots,n\}$ les sommets du graphe
\item Pour un chemin $p=\langle v_1,v_2,\ldots,v_l\rangle$, un sommet
\alert{intermédiaire} est un sommet de $p$ autre que $v_1$ ou $v_l$
\item Soit $d_{ij}^{(k)}$ le poids d'un plus court chemin entre $i$ et $j$ tel que tous les sommets intermédiaires sont dans le sous-ensemble de sommets $\{1,2,\ldots,k\}$
\item Soit un plus court chemin $p$ entre $i$ et $j$ avec tous les sommets dans $\{1,2,\ldots,k\}$:
\begin{itemize}
\item Si $k$ n'est pas un sommet intermédiaire de $p$, alors tous les sommets intermédiaires de $p$ sont dans $\{1,2,\ldots,k-1\}$
\item Si $k$ est un sommet intermédiaire, tous les sommets intermédiaires des sous-chemins entre $i$ et $k$ et entre $k$ et $j$ appartiennent à $\{1,2,\ldots,k-1\}$
\end{itemize}
\end{itemize}

\centerline{\includegraphics[width=6cm]{Figures/07-floydwarshall-recursion.pdf}}

\note{Pourquoi la deuxième: parce qu'un plus court-chemin ne contient pas de cycle. Au plus une fois $k$ dans le chemine entre $i$ et $j$}

\end{frame}



\begin{frame}{Algorithme de Floyd-Warshall}

\begin{itemize}
\item Formulation récursive:

\[d_{ij}^{(k)}=\left\{ \begin{array}{ll}
w(i,j)&\mbox{si }k=0,\\
\min(d_{ij}^{(k-1)},d_{ik}^{(k-1)}+d_{kj}^{(k-1)}) & \mbox{si } k\geq 1.
\end{array}\right.\]

\item Implémentation ascendante: $\Theta(|V|^3)$
\begin{itemize}
\item $W=(w_{ij})$ est la matrice d'adjacence pondérée
\item $w_{ij}=w(i,j)$ si $(i,j)\in E$, $+\infty$ sinon
\end{itemize}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Floyd-Warshall}(W,n)$}
         \li $D^{(0)}=W$
         \li \For $k=1$ \To $n$
         \li \Do let $D^{(k)}=(d_{ij}^{(k)})$ be a new $n\times n$ matrix
         \li \For $i=1$ \To $n$
         \li \Do \For $j=1$ \To $n$
         \li \Do $d_{ij}^{(k)}=\proc{min}(d_{ij}^{(k-1)},d_{ik}^{(k-1)}+d_{kj}^{(k-1)})$ \End\End\End
         \li \Return $D^{(n)}$
      \end{codebox}}
}
\end{center}


\end{itemize}

\note{\centerline{\includegraphics[width=11cm]{Figures/07-floydwarshall-exemple.pdf}}}

\end{frame}


\begin{frame}{Fermeture transitive d'un graphe}
\begin{itemize}
\item Soit un graphe dirigé $G=(V,E)$. La \alert{fermeture transitive} de $G$ est le graphe $G^*=(V,E^*)$ tel que:
$$E^*=\{(i,j): \exists\mbox{ un chemin de }i\mbox{ à }j\mbox{ dans }G\}$$

\item Exemple:

\bigskip

\centerline{\includegraphics[width=9cm]{Figures/07-closure.pdf}}

\bigskip

\item Solution directe:
\begin{itemize}
\item Assigner un poids $w_{ij}=1$ à toute arête $(i,j)\in E$
\item Appliquer l'algorithme de Floyd-Warshall
\item Si $d_{ij}<\infty$, il y a un chemin entre $i$ et $j$ dans $G$
\item Sinon, $d_{ij}=\infty$ et il n'y a pas de chemin
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Fermeture transitive d'un graphe}

Une solution plus simple en modifiant l'algorithme de Floyd-Warshall:
\begin{itemize}
\item Soit $t_{ij}^{(k)}=1$ s'il y a un chemin de $i$ à $j$ avec tous les n\oe uds intermédiaires dans $\{1,2,\ldots,k\}$, 0 sinon
\item On a:
{\small
\[t_{ij}^{(k)}=\left\{ \begin{array}{ll}
0&\mbox{si }k=0, i\neq j\mbox{ et }(i,j)\notin E\\
1& \mbox{si }k=0\mbox{ et }i=j\mbox{ ou }(i,j)\in E\\
t_{ij}^{(k-1)}\vee (t_{ik}^{(k-1)}\wedge t_{kj}^{(k-1)}) & \mbox{si } k\geq 1.
\end{array}\right.\]
}
\item Même implémentation que Floyd-Warshall
\begin{itemize}
\item on remplace $\min$ par $\vee$ et $+$ par $\wedge$
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Fermeture transitive d'un graphe: algorithme}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Transitive-closure}(G,n)$}
         \li Let $T^{(0)}=(t_{ij}^{(0)})$ be a new $n\times n$ matrix
         \li \For $i=1$ \To $n$
         \li \Do \For $j=1$ \To $n$
         \li \Do \If $i\isequal j$ or $(i,j)\in G.E$
         \li \Then $t_{ij}^{(0)}=1$
         \li \Else $t_{ij}^{(0)}=0$\End\End\End
         \li \For $k=1$ \To $n$
         \li \Do let $T^{k}=(t_{ij}^{(k)})$ be a new $n\times n$ matrix
         \li \For $i=1$ \To $n$
         \li \Do \For $j=1$ \To $n$
         \li \Do $t_{ij}^{(k)}= t_{ij}^{(k-1)}\vee (t_{ik}^{(k-1)}\wedge t_{kj}^{(k-1)})$ \End\End\End
         \li \Return $D^{(n)}$
      \end{codebox}}
}
\end{center}

\begin{itemize}
\item Complexité: $\Theta(|V|^3)$
\begin{itemize}
\item Idem Floyd-Warshall mais opérations plus simples
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Plus court chemin: synthèse}

\begin{itemize}
\item Origine unique, graphe dirigé acyclique:
\begin{itemize}
\item Relâchement en suivant un ordre topologique
\item $\Theta(|V|+|E|)$
\end{itemize}
\item Origine unique, graphe dirigé, poids positifs:
\begin{itemize}
\item Algorithme de Dijkstra
\item $\Theta(|E|\log |V|)$
\end{itemize}
\item Origine unique, graphe dirigé, poids quelconques:
\begin{itemize}
\item Algorithme de Bellman-Ford
\item $\Theta(|V|\cdot |E|)$
\end{itemize}
\item Toutes les paires, graphe dirigé ou non:
\begin{itemize}
\item Algorithme de Floyd-Warshall
\item $\Theta(|V|^3)$
\end{itemize}
\end{itemize}

\note{On peut transformer un graphe non dirigé en un graphe dirigé en introduisant deux arêtes par arête non dirigée}

\end{frame}

\section{Arbre couvrant}

\begin{frame}{Plan}

\tableofcontents[currentsection]

\end{frame}

\begin{frame}{Arbre couvrant}

\begin{itemize}
\item Définition: un \alert{arbre couvrant} {\it (spanning tree)}
  pour un graphe connexe $(V,E)$ non dirigé est un arbre (i.e. un
  graphe acyclique) $T$ tel que:
\begin{itemize}
\item l'ensemble des n\oe uds de $T$ est égal à $V$, et
\item l'ensemble des arcs de $T$ est un sous-ensemble de $E$
\end{itemize}
\item Construction: par un parcours en largeur ou en profondeur (graphe de liaison)
\item Exemple

\bigskip

\centerline{\includegraphics[width=3.5cm]{Figures/07-spanningtree.pdf}}

\end{itemize}

\end{frame}

\begin{frame}{Arbre couvrant de poids minimum}
\begin{itemize}
\item Définition: un \alert{arbre couvrant de poids minimum}, ACM, {\it (minimum
  spanning tree, MST)} pour un graphe pondéré connexe $(V,E)$ est un arbre $(V,E')$ tel que:
\begin{itemize}
\item $(V,E')$ est un arbre couvrant de $(V,E)$, et
\item la valeur de $\sum_{e\in E'} w(e)$ est minimale parmi tous les
  arbres couvrant de $(V,E)$, où $w(e)$ dénote le poids de l'arc $e$
\end{itemize}

\bigskip

\item Exemple:
\centerline{\includegraphics[width=6cm]{Figures/07-mstexemple.pdf}}
\end{itemize}

\end{frame}

\begin{frame}{Applications}

\centerline{\includegraphics[width=6cm]{Figures/07-applimst.pdf}}

\bigskip

\begin{itemize}
\item Conception de réseaux: connecter des entités en minimisant le coût de la connection
\begin{itemize}
\item Raccorder des maisons à un central téléphonique en minimisant les longueurs de cables
\item Elaborer un système routier pour connecter des maisons
\item ...
\end{itemize}
\item Dissémination de contenu/routage sur internet
\item Design de circuits imprimés
\item ...
\end{itemize}

\end{frame}

\begin{frame}{Approche générique}


\begin{itemize}
\item Idée:
\begin{itemize}
\item Un ACM est un sous-ensemble d'arêtes du graphe initial
\item On démarre avec un ensemble d'arêtes $A=\emptyset$ vide
\item On ajoute dans $A$ des arêtes en respectant l'invariant suivant:
\begin{itemize}
\item Il existe un ACM qui contient les arêtes de $A$
\end{itemize}
\item S'il existe un ACM contenant les arêtes de $A$, une arête $(u,v)$
  est \alert{sûre} pour $A$ ssi il existe un ACM contenant les arêtes de $A\cup \{(u,v)\}$
\end{itemize}

\bigskip

\item Algorithme générique:

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Generic-MST}(G,w)$}
        \li $A=\emptyset$
        \li \While $A$ is not a spanning tree
        \li \Do find an edge $(u,v)$ that is safe for $A$
        \li $A=A\cup \{(u,v)\}$\End
        \li \Return $A$
      \end{codebox}}
}
\end{center}

\item Comment trouver des arêtes sûres ?
\end{itemize}

\note{Discuter de la correction: assez évident}

\end{frame}

\begin{frame}{Arêtes sûres}
\begin{itemize}
\item Soit $S\subset V$ et $A\subseteq E$:
\begin{itemize}
\item Une \alert{coupure} ({\it cut}) $(S,V\setminus S)$ est une partition des sommets en deux ensembles disjoints $S$ et $V\setminus S$
\item Une arête \alert{traverse} ({\it crosses}) une coupure $(S,V\setminus
  S)$ si une extrémité est dans $S$ et l'autre dans $V\setminus S$
\item Une coupure \alert{respecte} $A$ ssi il n'y a pas d'arête dans $A$ qui traverse la coupure
\end{itemize}

\bigskip

\item \alert{Théorème:} Soit $A$ un sous-ensemble d'un ACM,
  $(S,V\setminus S)$ une coupure qui respecte $A$ et $(u,v)$ une arête
  de \alert{poids minimal} qui traverse la coupure $(S,V\setminus
  S)$. $(u,v)$ est sûre pour $A$.\\
\medskip
{\it (Propriété des choix gloutons optimaux)}
\end{itemize}

\end{frame}

\begin{frame}{Arêtes sûres}

\centerline{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\includegraphics[width=4cm]{Figures/07-mstproof.pdf}}
\vspace{-0.8cm}
\alert{Preuve:}
\begin{itemize}
\item Soit $T$ un ACM qui inclut $A$ % existe puisque $A$ est un sous-ensemble d'un MST
\item Supposons que $T$ ne contienne pas $(u,v)$ et montrons qu'il est possible de construire un arbre $T'$ qui inclut $A\cup\{(u,v)\}$
\item Puisque $T$ est un arbre, il n'y a qu'un unique chemin $p$ entre
  $u$ et $v$ et ce chemin traverse la coupure $(S,V\setminus S)$.
\item Soit $(x,y)$ une arête de $p$ qui traverse la coupure $(S,V\setminus S)$
\item Puisque $(u,v)$ est l'arête de poids minimum qui traverse la coupure, on a:
$$w(u,v)\leq w(x,y)$$
\end{itemize}

\end{frame}

\begin{frame}{Arêtes sûres}

\centerline{\includegraphics[width=4cm]{Figures/07-mstproof.pdf}}

\begin{itemize}
\item Puisque la coupure respecte $A$, l'arête $(x,y)$ n'est pas dans $A$
\item Soit $T'=(T\setminus\{(x,y)\})\cup \{(u,v)\}$:
\begin{itemize}
\item $T'$ est un spanning tree
\item $w(T')=w(T)-w(x,y)+w(u,v)\leq w(T)$ puisque $w(u,v)\leq w(x,y)$
\end{itemize}
\item $T'$ est donc bien un ACM tel que $A\cup\{(u,v)\}\subseteq T'$
\item $\Rightarrow (u,v)$ est sûre pour $A$
\end{itemize}\qed

\end{frame}

\begin{frame}{Algorithme de Kruskal}
\begin{itemize}
\item Approche gloutonne:
\begin{itemize}
\item On construit incrémentalement une forêt (c'est-à-dire, un
  ensemble d'arbres), en ajoutant progressivement des arêtes à un
  graphe initialement dépourvu d'arcs
\item On maintient en permanence une partition du graphe en cours de construction en ses composantes connexes
\item Pour relier des composantes connexes, on choisit à chaque fois l'arête de poids minimal qui les connecte
\item On s'arrête dès qu'il ne reste plus qu'une composante connexe
\end{itemize}

\bigskip

\item Correction:
\begin{itemize}
\item Puisqu'on connecte à chaque fois deux composantes connexes
  disjointes, le graphe reste acyclique et à la terminaison, on obtient un arbre couvrant
\item Puisqu'on sélectionne une arête de poids minimal à chaque étape,
  le théorème précédent garantit qu'on arrivera à un ACM
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Algorithme de Kruskal}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Kruskal}(G,w)$}
        \li $A=\emptyset$
        \li $P=\emptyset$
        \li \For each vertex $v \in G.V$
        \li \Do $P=P\cup\{\{v\}\}$\End
        \li \For each $(u,v)\in G.E$ taken into nondecreasing order of weight $w$
        \li \Do $P_1=$ subset in $P$ containing $u$
        \li $P_2=$ subset in $P$ containing $v$
        \li \If $P_1\neq P_2$
        \li \Then $A=A\cup\{(u,v)\}$
        \li Merge $P_1$ and $P_2$ in $P$\End\End
        \li \Return $A$
      \end{codebox}}
}
\end{center}

\begin{itemize}
\item Les choix des composantes connexes à combiner est arbitraire
\item On fixe cet ordre en parcourant les arêtes par ordre croissant
\end{itemize}

\end{frame}

\begin{frame}{Illustration}

%\begin{columns}
%\begin{column}{5cm}
\centerline{\includegraphics[width=6cm]{Figures/07-mstexemple.pdf}}
%\end{column}
%\begin{column}{5cm}
\begin{center}
\footnotesize
\begin{tabular}{lll}
& & $P$\\
\hline
 & & $\{\{a\},\{b\},\{c\},\{d\},\{e\},\{f\},\{g\},\{h\},\{i\}\}$\\
\alert{$(c,f)$} & fusion & $\{\{a\},\{b\},\{c,f\},\{d\},\{e\},\{g\},\{h\},\{i\}\}$\\
\alert{$(g,i)$} & fusion & $\{\{a\},\{b\},\{c,f\},\{d\},\{e\},\{g,i\},\{h\}\}$\\
\alert{$(e,f)$} & fusion & $\{\{a\},\{b\},\{c,f,e\},\{d\},\{g,i\},\{h\}\}$\\
$(c,e)$ & rejet & \\
\alert{$(d,h)$} & fusion & $\{\{a\},\{b\},\{c,f,e\},\{d,h\},\{g,i\}\}$\\
\alert{$(f,h)$} & fusion & $\{\{a\},\{b\},\{c,f,e,d,h\},\{g,i\}\}$\\
$(e,d)$ & rejet & \\
\alert{$(b,d)$} & fusion & $\{\{a\},\{b,c,f,e,d,h\},\{g,i\}\}$\\
\alert{$(d,g)$} & fusion & $\{\{a\},\{b,c,f,e,d,h,g,i\}\}$\\
$(b,c)$ & rejet & \\
$(g,h)$ & rejet & \\
\alert{$(a,b)$} & fusion & $\{\{a,b,c,f,e,d,h,g,i\}\}$\\
\end{tabular}
\end{center}
%\end{column}
%\end{columns}

\end{frame}

\begin{frame}{Implémentation}
\begin{itemize}
\item Problème: comment représenter les partitions de l'ensemble des sommets du graphe ?
\item Une solution possible:
\begin{itemize}
\item On numérote les parties $P_1$, $P_2$,\ldots, $P_k$ d'une partition $\{P_1,P_2,\ldots, P_k\}$ à l'aide des nombres de 1 à $k$
\item Pour chaque sommet $v$, on retient le numéro de la partie à
  laquelle il appartient (attribut $v.p$)
\item Pour chaque numéro de partie, on retient une liste des sommets contenus dans cette partie
\item Lors de la fusion de deux parties, on insère la plus petite
  partie à fusionner dans l'autre et on met à jour les numéros de partie
\end{itemize}
\item Complexité:
\begin{itemize}
\item Trouver la partie associée à un sommet: $O(1)$
\item Fusionner deux parties de tailles $n_1$ et $n_2$, avec $n_1<n_2$: $\Theta(n_1)$
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Complexité}
\begin{itemize}
\item Initialisation: $O(|V|)$
\item Tri des arêtes: $O(|E|\log |V|)$
\begin{itemize}
\item Tri: $O(|E|\log |E|)$
\item Or, $|E|<|V|^2 \Rightarrow \log |E|=O(2\log|V|)=O(\log |V|)$
\end{itemize}
\item Coût total des fusions: $O(|V|\log |V|)$
\begin{itemize}
\item Chaque fusion est linéaire par rapport à la taille de la plus
  petite partie
\item Chaque fusion produit un nouvelle partie au moins deux fois plus
  grande que la plus petite
\item Chaque sommet n'est ajouté à une partie qu'au plus $O(\log|V|)$ fois
\end{itemize}
\item Temps d'exécution total: $O(|E|\log |V|+|V|\log|V|) = O(|E|\log |V|)$
\begin{itemize}
\item Car $|E|$ domine $|V|$ dans le cas d'un graphe connexe
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Algorithme de Prim}

\begin{itemize}
\item Principe:
\begin{itemize}
\item $A$ est toujours un arbre (plus une forêt)
\item Initialisé comme une seule racine $r$ choisie de manière arbitraire
\item A chaque étape, choisir une arête de poids minimal traversant la
  coupure $(V_A,V\setminus V_A)$, où $V_A$ est l'ensemble des sommets
  connectés par des arêtes de $A$, et l'ajouter à $A$.
\end{itemize}

\bigskip

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Prim}(G,w,r)$}
        \li $A=\emptyset$
        \li $V_A=\{r\}$
        \li \While $|V_A|<|G.V|$
        \li \Do $(u,v)=$"an edge of minimal weight from $V_A$ to $V\setminus V_A$"
        \li $V_A=V_A\cup \{u,v\}$
        \li $A=A\cup \{(u,v)\}$\End
        \li \Return $A$
      \end{codebox}}
}
\end{center}

\bigskip

\item Correction: toujours en application du théorème
\end{itemize}

\end{frame}

\begin{frame}{Implémentation}

\begin{itemize}
\item Comment extraire efficacement l'arête de poids minimal?
\item Utiliser une file à priorité:
\begin{itemize}
\item Chaque élément de la file est un sommet de $V\setminus V_A$ (pas
  encore couvert par l'arbre courant)
\item La clé de $v$ est le poids minimum de tout arête $(u,v)$ où $u\in V_A$
\item Cette clé est mis à jour à chaque ajout d'un sommet dans $V_A$
\end{itemize}

\bigskip

\item L'arbre est ``stocké'' par le biais d'un pointeur $v.\pi$
\begin{itemize}
\item $v.\pi$ est le parent de $v$ dans l'arbre couvrant minimal
\item $v.\pi=\const{NIL}$ si $v=r$ ou $v$ n'a pas de parents
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Implémentation}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Prim}(G,w,r)$}
        \li $Q=\emptyset$
        \li \For each $u\in G.V$
        \li \Do $u.key=\infty$
        \li $u.\pi=\const{NIL}$
        \li $\proc{Insert}(Q,u)$\End
        \li $\proc{Decrease-key}(Q,r,0)$ \Comment $r.key=0$
        \li \While $Q\neq \emptyset$
        \li \Do $u=\proc{Extract-min}(Q)$
        \li \For each $v\in G.Adj[u]$
        \li \Do \If $v\in Q$ and $w(u,v)< v.key$
        \li \Then $v.\pi=u$
        \li $\proc{Decrease-Key}(Q,v,w(u,v))$\End\End\End
      \end{codebox}}
}
\end{center}

\end{frame}

\begin{frame}{Illustration}

\centerline{\includegraphics[width=6cm]{Figures/07-mstexemple.pdf}}

A partir du n\oe ud $d$
\begin{center}\small
\begin{tabular}{cccccccccc}
N\oe ud  & $Q^0$ & $Q^1$ & $Q^2$ & $Q^3$ & $Q^4$ & $Q^5$ & $Q^6$ & $Q^7$ & $Q^8$\\
\hline
$a$ & $\infty$ & $\infty$& $\infty$& $\infty$ & 12 & 12 & 10 & 10 & 10\\
$b$ & $\infty$ & 8& 8 & 8 & 8 & 8\\%%
$c$ & $\infty$ & $\infty$& $\infty$ & 1\\%%
$d$ & 0 \\%%
$e$ & $\infty$ & 7& 7 & 3 & 3\\%%
$f$ & $\infty$ & $\infty$ & 6\\%%
$g$ & $\infty$ & 8 & 8 & 8 & 8 & 8\\%%
$h$ & $\infty$ & 5\\%%
$i$ & $\infty$ & $\infty$ & 11 & 11 & 11 & 11 & 2\\%%
\end{tabular}\\

\medskip

{\footnotesize (valeurs de clé des sommets dans $Q$ au fur et à mesure des itérations)}
\end{center}


\end{frame}

\begin{frame}{Complexité}

\begin{itemize}
\item En supposant que $Q$ est implémentée à l'aide d'un tas (min)
\item Initialisation et première boucle $\For$: $O(|V|\log|V|)$
\item Diminuer la clé de $r$: $O(\log |V|)$
\item Boucle $\While$: $O(|V|\log|V|+|E|\log |V|)$
\begin{itemize}
\item $|V|$ appels à $\proc{Extract-Min} \Rightarrow O(|V|\log |V|)$
\item $|E|$ appels à $\proc{Decrease-Key} \Rightarrow O(|E|\log|V|)$
\end{itemize}
\item Temps d'exécution total: $O(|E|\log |V|+|V|\log|V|) = O(|E|\log |V|)$
\begin{itemize}
\item Car $|E|$ domine $|V|$ dans le cas d'un graphe connexe
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\centerline{Fin}

\bigskip

Pour aller plus loin:\\
\centerline{\includegraphics[width=5cm]{Figures/clrscover.pdf}}

\end{frame}
