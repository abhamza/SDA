\part{Résolution de problèmes}

% Rajouter les slides d'outline et un découpe des sections par exemple
% Mettre Exemple 1, 2, etc.
% maximum/maximal ?

\begin{frame}{Plan}

\tableofcontents[hideallsubsections]

\end{frame}

\section{Introduction}

\begin{frame}{Méthodes de résolution de problèmes}

Quelques approches génériques pour aborder la résolution d'un problème:
\begin{itemize}
\item \alert{Approche par force brute:} résoudre directement le problème, à partir de sa définition ou par une recherche exhaustive
\semitransp{\item Diviser pour régner: diviser le problème en sous-problèmes, les résoudre, fusionner les solutions pour obtenir une solution au problème original
\item Programmation dynamique: obtenir la solution optimale à un problème en combinant des solutions optimales à des sous-problèmes similaires plus petits et se chevauchant
\item Approche gloutonne: construire la solution incrémentalement, en optimisant de manière aveugle un critère local}
\end{itemize}

\end{frame}

\section{Approche par force brute}

\begin{frame}{Approche par force brute (brute-force)}
\begin{itemize}
\item Consiste à appliquer la solution la plus directe à un problème
\item Généralement obtenue en appliquant à la lettre la définition du problème
\item Exemple simple:
\begin{itemize}
\item Rechercher un élément dans un tableau (trié ou non) en le parcourant linéairement
\item Calculer $a^n$ en multipliant $a$ $n$ fois avec lui-même
\item Implémentation récursive naïve du calcul des nombres de Fibonacci
\item \ldots
\end{itemize}
\item Souvent pas très efficace en terme de temps de calcul mais facile à implémenter et fonctionnel
\end{itemize}

\end{frame}

\begin{frame}{Exemple: tri}

Approches par force brute pour le tri:
\begin{itemize}
\item Un tableau est trié (en ordre croissant) si tout élément est plus petit que l'élément à sa droite
\item $\Rightarrow$ tri à bulle: parcourir le tableau de gauche à droite en échangeant toutes les paires d'éléments consécutifs ne respectant pas cette définition
\item Complexité: $O(n^2)$
\item $\Rightarrow$ tri par sélection: trouver le minimum du tableau, l'échanger avec le premier élément, répéter pour trier le reste du tableau
\item Complexité: $\Theta(n^2)$
\end{itemize}
\end{frame}

\begin{frame}{Recherche exhaustive}
\begin{itemize}
\item Une solution par force brute au problème de la recherche d'un élément possédant une propriété particulière
\item Générer toutes les solutions possibles jusqu'à en obtenir une qui possède la propriété recherchée
\item Exemple pour le tri:
\begin{itemize}
\item Générer toutes les permutations du tableau de départ (une et une seule fois)
\item Vérifier si chaque tableau permuté est trié. S'arrêter si c'est le cas.
\item Complexité: $O(n!\cdot n)$
\end{itemize}
\item Généralement utilisable seulement pour des problèmes de petite taille
\item Dans la plupart des cas, il existe une meilleure solution
\item Dans certains cas, c'est la seule solution possible
\end{itemize}
\end{frame}

\begin{frame}{Problème du voyageur de commerce}
\begin{itemize}
\item Etant donné $n$ villes et les distances entre ces villes
\item Trouver le plus court chemin qui passe par toutes les villes
  exactement une fois avant de revenir à la ville de départ
\end{itemize}
\begin{columns}
\begin{column}{5cm}
\centerline{\includegraphics[width=3cm]{Figures/06-tsp.pdf}}
\end{column}
\begin{column}{5cm}
\footnotesize
\begin{tabular}{ll}
Tour & Coût\\
\hline
A-B-C-D-A & 17\\
A-B-D-C-A & 21\\
A-C-B-D-A & 20\\
A-C-D-B-A & 21\\
A-D-B-C-A & 20\\
A-D-C-B-A & 17\\
\end{tabular}
\end{column}
\end{columns}

\begin{itemize}
\item Recherche exhaustive: $O(n!)$
\item On n'a pas encore pu trouver un algorithme de complexité polynomiale (et il y a peu de chance qu'on y arrive)
\end{itemize}

\end{frame}

\begin{frame}{Force brute/recherche exhaustive}
Avantages:
\begin{itemize}
\item Simple et d'application très large
\item Un bon point de départ pour trouver de meilleurs algorithmes
\item Parfois, faire mieux n'en vaut pas la peine
\end{itemize}

\bigskip

Inconvénients:
\begin{itemize}
\item Produit rarement des solutions efficaces
\item Moins éléguant et créatif que les autres techniques
\end{itemize}

\bigskip

Dans ce qui suit, on commencera la plupart du temps par fournir la solution par force brute des problèmes, qu'on cherchera ensuite à résoudre par d'autres techniques

\end{frame}

% truc interessant:

\section{Diviser pour régner}

\begin{frame}{Méthodes de résolution de problèmes}

Quelques approches génériques pour aborder la résolution d'un problème:
\begin{itemize}
\item \alert{Approche par force brute:} résoudre directement le problème, à partir de sa définition ou par une recherche exhaustive
\item \alert{Diviser pour régner:} diviser le problème en sous-problèmes, les résoudre, fusionner les solutions pour obtenir une solution au problème original
\semitransp{
\item {Programmation dynamique:} obtenir la solution optimale à un problème en combinant des solutions optimales à des sous-problèmes similaires plus petits et se chevauchant
\item {Approche gloutonne:} construire la solution incrémentalement, en optimisant de manière aveugle un critère local}
\end{itemize}

\end{frame}

\begin{frame}{Plan}

\tableofcontents[currentsection,hideothersubsections]

\end{frame}

\begin{frame}{Approche diviser-pour-régner {\it (Divide and conquer)}}

Principe général:
\begin{itemize}
\item Si le problème est trivial, on le résoud directement
\item Sinon:
\begin{enumerate}
\item Diviser le problème en sous-problèmes de taille inférieure (Diviser)
\item Résoudre récursivement ces sous-problèmes (Régner)
\item Fusionner les solutions aux sous-problèmes pour produire une solution au problème original
\end{enumerate}
\end{itemize}

\end{frame}

\begin{frame}{Exemples déjà rencontrés}

\begin{itemize}
\item \alert{Merge sort:}
\begin{enumerate}
\item Diviser: Couper le tableau en deux sous-tableaux de même taille
\item Régner: Trier récursivement les deux sous-tableaux
\item Fusionner: fusionner les deux sous-tableaux
\end{enumerate}
Complexité: $\Theta(n\log n)$ (force brute: $\Theta(n^2)$)
\item \alert{Quicksort:}
\begin{enumerate}
\item Diviser: Partionner le tableau selon le pivot
\item Régner: Trier récursivement les deux sous-tableaux
\item Fusionner: /
\end{enumerate}
Complexité en moyenne: $\Theta(n\log n)$ (force brute: $\Theta(n^2)$)
\item \alert{Recherche binaire} (dichotomique):
\begin{enumerate}
\item Diviser: Contrôler l'élement central du tableau
\item Régner: Chercher récursivement dans un des sous-tableaux
\item Fusionner: trivial
\end{enumerate}
Complexité: $O(\log n)$ (force brute: $O(n)$)
\end{itemize}

\end{frame}

\subsection{Exemple 1: calcul du minimum/maximum d'un tableau}

\begin{frame}{Exemple 1: Calcul du minimum/maximum d'un tableau}

\begin{itemize}
\item Approche par force brute pour trouver le minimum ou le maximum d'un tableau
\end{itemize}

\begin{columns}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Min}(A)$}
        \li $min\gets A[1]$
        \li \For $i\gets 2$ \To $\attrib{A}{length}$
        \li \Do \If $min>A[i]$
        \li \Then $min\gets A[i]$\End\End
        \li \Return $min$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{5cm}
\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max}(A)$}
        \li $max\gets A[1]$
        \li \For $i\gets 2$ \To $\attrib{A}{length}$
        \li \Do \If $max<A[i]$
        \li \Then $max\gets A[i]$\End\End
        \li \Return $max$
      \end{codebox}}
}
\end{center}
\end{column}
\end{columns}

\bigskip

\begin{itemize}
\item Complexité: $\Theta(n)$ ($n-1$ comparaisons)
\item Peut-on faire mieux ?
\begin{itemize}
\item<2> Non, pas en notation asymptotique (le problème est $\Theta(n)$)
\item<2> Par contre, on peut diminuer le nombre total de comparaisons pour calculer à la fois le minimum et le maximum
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Calcul simultané du minimum et du maximum}

\begin{itemize}
\item Approche diviser-pour-régner pour le calcul simultané du minimum et du maximum
\end{itemize}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max-Min}(A,p,r)$}
        \li \If $\id{r}-\id{p}\leq 1$
        \li \Then \If $A[p]<A[r]$
        \li \Then \Return $(A[r],A[p])$
        \li \Else \Return $(A[p],A[r])$\End\End
        \li $q\gets \lfloor\frac{p+r}{2}\rfloor$
        \li $(max1,min1)=\proc{Max-Min}(A,p,q)$
        \li $(max2,min2)=\proc{Max-Min}(A,q+1,r)$
        \li \Return $(\proc{max}(max1,max2),\proc{min}(min1,min2))$
      \end{codebox}}
}
\end{center}

\centerline{Appel initial: $\proc{Max-Min}(A,1,A.length)$}

\bigskip

\begin{itemize}
\item Correct ? Oui (preuve par induction)
\item Complexité ?
\end{itemize}

\end{frame}

\begin{frame}{Analyse de complexité}

\begin{itemize}
\item En supposant que $n$ est une puissance de 2, le nombre de
  comparaisons $T(n)$ est donné par: {\small
\[
T(n) = \left\{
\begin{array}{ll}
 1 & \mbox{si }n=2\\
2 T(n/2)+2 & \mbox{sinon}
\end{array}
\right.
\]}
qui se résoud en:
{\footnotesize
\begin{eqnarray*}
T(n) & = & 2 T(n/2)+2\\
%& = & 2(2 T(n/4)+2)+2\\
& = & 4 T(n/4)+4+2\\
& = & 8 T(n/4)+8+4+2\\
& = & 2^i T(n/2^i)+\sum_{j=1}^i 2^j\\
& = & 2^{\log_2(n)-1} T(2)+\sum_{j=1}^{\log_2(n)-1} 2^j\\
& = & 3/2 n -2
\end{eqnarray*}}
\item C'est-à-dire 25\% de comparaisons en moins que les méthodes séparées
\end{itemize}

\end{frame}

\subsection{Exemple 2: Recherche de pics}

\begin{frame}{Exemple 2: Recherche de pics}

\centerline{\includegraphics[width=6cm]{Figures/06-peakfinding.pdf}}

\bigskip

\begin{itemize}
\item Soit un tableau $A[1\twodots \attrib{A}{length}]$. On supposera
  que $A[0]=A[\attrib{A}{length}+1]=-\infty$.
\item Définition: $A[i]$ est un \alert{pic} s'il n'est pas plus petit que ses voisins:
$$A[i-1]\leq A[i]\geq A[i+1]$$
($A[i]$ est un maximum local)
\item \alert{But:} trouver un pic dans le tableau (n'importe lequel)
\item Note: il en existe toujours un
\end{itemize}

\end{frame}

\begin{frame}{Approche par force brute}
\begin{itemize}
\item Tester toutes les positions séquentiellement:

\bigskip

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Peak1d}(A)$}
        \li \For $i\gets 1$ \To $\attrib{A}{length}$
        \li \Do \If $A[i-1]\leq A[i]\geq A[i+1]$
        \li \Then \Return $i$\End\End
      \end{codebox}}
}
\end{center}

\bigskip

\item Complexité: $O(n)$ dans le pire cas
\end{itemize}

\end{frame}

\begin{frame}{Approche par force brute 2}
\begin{itemize}
\item Le maximum global du tableau est un maximum local et donc un pic

\bigskip

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Peak1d}(A)$}
        \li $m\gets A[0]$
        \li \For $i\gets 1$ \To $\attrib{A}{length}$
        \li \Do \If $A[i]>A[m]$
        \li \Then $m\gets i$\End\End
        \li \Return m
      \end{codebox}}
}
\end{center}

\bigskip

\item Complexité: $\Theta(n)$ dans tous les cas
\end{itemize}

\end{frame}

\begin{frame}{Une meilleure idée}

Approche diviser-pour-régner:
\begin{itemize}
\item Sonder un élément $A[i]$ et ses voisins $A[i-1]$ et $A[i+1]$
\item Si c'est un pic: renvoyer $i$
\item Sinon:
\begin{itemize}
\item les valeurs doivent croître au moins d'un côté
$$A[i-1]>A[i]\mbox{ ou }A[i]<A[i+1]$$
%\item Il doit y avoir un pic de ce côté
\item Si $A[i-1]>A[i]$, on cherche le pic dans $A[1\twodots i-1]$
\item Si $A[i+1]>A[i]$, on cherche le pic dans $A[i+1\twodots \attrib{A}{length}]$
\end{itemize}

\bigskip

\centerline{\includegraphics[width=7cm]{Figures/06-peakfinding-idea.pdf}}

\item A quel position $i$ faut-il sonder ?
\end{itemize}

\note{montrer graphiquement\\
Il faut sonder au milieu pour accélerer les calculs}
\end{frame}

\begin{frame}{Algorithme}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Peak1d}(A,p,r)$}
        \li $q\gets \lfloor\frac{p+r}{2}\rfloor$
        \li \If $A[q-1]\leq A[q]\geq A[q+1]$
        \li \Then \Return $q$
        \li \ElseIf $A[q-1]>A[q]$
        \li \Then \Return $\proc{Peak1d}(A,p,q-1)$
        \li \ElseIf $A[q]<A[q+1]$
        \li \Then \Return $\proc{Peak1d}(A,q+1,r)$\End
      \end{codebox}}
}
\end{center}

\centerline{Appel initial: $\proc{Peak1d}(A,1,A.length)$}

\end{frame}

\begin{frame}{Analyse}
\begin{itemize}
\item Correction: oui
\begin{itemize}
\item On doit prouver qu'il y aura un pic du côté choisi
\item Preuve par l'absurde:
\begin{itemize}
\item Supposons que $A[q+1]>A[q]$ et qu'il n'y ait pas de pic dans $A[q+1\twodots r]$
\item On doit avoir $A[q+2]>A[q+1]$ (sinon $A[q+1]$ serait un pic)
\item On doit avoir $A[q+3]>A[q+2]$ (sinon $A[q+2]$ serait un pic)
\item \ldots
\item On doit avoir $A[r]>A[r-1]$ (sinon $A[r-1]$ serait un pic)
\item Comme $A[r]>A[r+1]=-\infty$, $A[r]$ est un pic, ce qui contredit l'hypothèse
\end{itemize}
\end{itemize}

\bigskip

\item Complexité:
\begin{itemize}
\item Dans le pire cas, on a $T(n)=T(n/2)+c_1$ et $T(1)=c_2$ (idem recherche binaire)
\item $\Rightarrow T(n)=O(\log n)$
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Extension à un tableau 2D}

\begin{columns}
\begin{column}{5cm}
\begin{itemize}
\item Soit une matrice $n\times n$ de nombres
\item Trouver un élement plus grand ou égal à ses 4 voisins (max)
\end{itemize}

\bigskip

\centerline{\includegraphics[width=2cm]{Figures/06-2dpeak-constraints.pdf}}
\end{column}
\begin{column}{5cm}
\centerline{\includegraphics[width=5cm]{Figures/06-2dpeak.pdf}}
~\hfill{\scriptsize(Demaine \& Leiserson)}
\end{column}
\end{columns}

\bigskip

\begin{itemize}
\item Approche par force brute: $O(n^2)$
\item Recherche du maximum: $\Theta(n^2)$
\end{itemize}

\end{frame}

\begin{frame}{Approche diviser-pour-régner}

\begin{columns}
\begin{column}{7cm}
\begin{itemize}
\item Chercher le maximum global dans la colonne \alert{centrale}
\item Si c'est un pic, le renvoyer
\item Sinon appeler la fonction récursivement sur les colonnes à
  gauche (resp. droite) si le voisin à gauche (resp. droite) est plus grand
\end{itemize}

\end{column}
\begin{column}{4cm}
\centerline{\includegraphics[width=4cm]{Figures/06-2dpeak-dc.pdf}}
~\hfill{\scriptsize(Demaine \& Leiserson)}
\end{column}
\end{columns}

\bigskip

\end{frame}

\begin{frame}{Analyse: correction}

\begin{itemize}
\item On doit prouver qu'il y a bien un pic du côté choisi
\item Preuve par l'absurde:
\begin{itemize}
\item Supposons qu'il n'y ait pas de pic
\item Soient $A[i,j]$ le maximum de la colonne centrale et $A[i,k]$ le voisin le plus grand ($k=j-1$ ou $k=j+1$)
\item $A[i,k]$ doit avoir un voisin $A[p_1,q_1]$ avec une valeur plus élevée (sinon, ce serait un pic)
\item $A[p_1,q_1]$ doit avoir un voisin $A[p_2,q_2]$ avec une valeur plus élevée (sinon, ce serait un pic)
\item \ldots
\item Le voisin doit toujours rester du même côté de la colonne
  centrale (puisque $A[i,k]>A[i,j]$ et $A[i,j]$ est le maximum de la
  colonne $j$)
\item A un certain point, on va manquer de points
\item Il doit donc y avoir un pic
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Analyse: complexité}

\begin{itemize}
\item $O(n)$ pour trouver le maximum d'une colonne
\item $O(\log n)$ itérations
\item $O(n\log n)$ au total
\bigskip

\item Peut-on faire mieux ? Oui, il est possible de proposer un algorithme en $O(n)$ (pas vu dans ce cours)
\end{itemize}

\end{frame}

\subsection{Exemple 3: sous-séquence de somme maximale}

\begin{frame}{Exemple 3: Achat/vente d'actions}

\centerline{\includegraphics[width=8cm]{Figures/06-stockprice.pdf}}

\bigskip

\begin{itemize}
\item Soit le prix d'une action au cours de $n$ jours consécutifs (prix à la fermeture)
\item On aimerait déterminer rétrospectivement:
\begin{itemize}
\item à quel moment, on aurait dû acheter et
\item à quel moment, on aurait dû vendre
\end{itemize}
de manière à maximiser notre gain
\end{itemize}

\end{frame}

\begin{frame}{Exemple 3: Achat/vente d'actions}

Première stratégie:
\begin{itemize}
\item Acheter au prix minimum, vendre au prix maximum
\pause
\item Pas correct: Le prix maximum ne suit pas nécessairement le prix minimum
\end{itemize}

\bigskip
\pause
Deuxième stratégie:
\begin{itemize}
\item Soit acheter au prix minimum et vendre au prix le plus élevé qui suit
\item Soit vendre au prix maximum et acheter au prix le plus bas qui précède
\pause
\item Pas correct:
\end{itemize}
\vspace{-0.5cm}
~\hfill\includegraphics[width=4cm, height=2cm]{Figures/06-stockprice-2.pdf}

\bigskip
\vspace{-0.5cm}
\pause
Troisième stratégie:
\begin{itemize}
\item Tester toutes les paires (force brute)
\item Correct ? Complexité ?
\end{itemize}
\end{frame}

\begin{frame}{Achat/vente d'actions: transformation}

\centerline{\includegraphics[width=11cm]{Figures/06-stockprice-3.pdf}}

\bigskip

\begin{itemize}
\item Transformation du problème:
\begin{itemize}
\item Calculer le tableau $A[i]=\mbox{(prix du jour i)-(prix du jour i-1)}$ (de taille $A.length=n$ en supposant qu'on démarre avec un prix au jour 0)
\item Déterminer la sous-séquence  non vide contiguë de somme maximale dans $A$
\item Soit $A[i\twodots j]$ cette sous-séquence. Il aurait fallu acheter juste avant le jour $i$ (juste après le jour $i-1$) et vendu juste après le jour $j$.
\end{itemize}
\item Exemple dans le tableau ci-dessus: $A[8\twodots 11]$ est la sous-séquence maximale de somme 43 $\Rightarrow$ acheter juste avant le jour 8 et vendre juste après le jour 11.
\item Si on peut trouver la sous-séquence maximale dans un tableau, on aura une solution à notre problème d'achat/vente d'actions
%\item Est-ce que la transformation est utile ?
\end{itemize}
\end{frame}

\begin{frame}{Approche par force brute}
\centerline{\includegraphics[width=8cm]{Figures/06-maxsubarray.pdf}}

\bigskip

\begin{itemize}
\item Implémentation naïve:
\begin{itemize}
\item On génère tous les sous-tableaux 
\item On calcule la somme des éléments de chaque sous-tableau
\item On renvoie les bornes du (d'un) sous-tableau de somme maximale
\end{itemize}
\item Complexité: $\Theta(n^2)$ sous-tableaux et $O(n)$ pour le calcul
  de la somme d'un sous-tableau $\Rightarrow$ $O(n^3)$
\item On peut l'implémenter en $\Theta(n^2)$
\end{itemize}

\end{frame}

\begin{frame}{Approche par force brute}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max-subarray-brute-force}(A)$}
        \li $n=A.length$
        \li $\id{max-so-far}\gets -\infty$
        \li \For $l\gets 1$ \To n
        \li \Do $sum=0$
        \li \For $h\gets l$ \To n
        \li \Do $sum\gets sum+A[h]$
        \li \If $sum>\id{max-so-far}$
        \li \Then $\id{max-so-far}=sum$
        \li $low=l$
        \li $high=h$\End\End\End
        \li \Return $(low,high)$
      \end{codebox}}
}
\end{center}

Complexité: $\Theta(n^2)$\\

Peut-on faire mieux ?

\end{frame}

\begin{frame}{Approche diviser-pour-régner}

\begin{itemize}
\item Nouveau problème:
\begin{itemize}
\item trouver un sous-tableau maximal dans $A[low\twodots high]$
\item fonction $\proc{maximum-subarray}(A,low,high)$
\end{itemize}
\item Diviser:
\begin{itemize}
\item diviser le sous-tableau en deux sous-tableaux de tailles aussi proches que possible
\item choisir $mid=\lfloor (low+high)/2 \rfloor$
\end{itemize}
\item Régner:
\begin{itemize}
\item trouver récursivement les sous-tableaux maximaux dans ces deux sous-tableaux
\item appeler $\proc{maximum-subarray}(A,low,mid)$ et $\proc{maximum-subarray}(A,mid+1,high)$
\end{itemize}
\item Fusionner: ?
\end{itemize}

\end{frame}

\begin{frame}{Approche diviser-pour-régner}

\centerline{\includegraphics[width=7cm]{Figures/06-maxsubarray-cross.pdf}}

\bigskip

\begin{itemize}
\item Fusionner:
\begin{itemize}
\item Rechercher un sous-tableau maximum qui traverse la jonction
\item Choisir la meilleure solution parmi les 3
\end{itemize}
\item $\proc{max-crossing-subarray}(A,low,mid,high)$
\begin{itemize}
\item Force brute: $\Theta(n^2)$ (car n/2 choix pour l'extrémité gauche, n/2 choix pour l'extrémité droite)
\item Meilleure solution: on recherche indépendamment les extrémités gauche et droite
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{$\proc{max-crossing-subarray}$}

{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max-crossing-subarray}(A,low,mid,high)$}
        \li $\id{left-sum}=-\infty$
        \li $sum=0$
        \li \For $i\gets mid$ \Downto $low$
        \li \Do $sum=sum+A[i]$
        \li \If $sum>\id{left-sum}$
        \li \Then $\id{left-sum}=sum$
        \li $\id{max-left}=i$\End\End
        \li $\id{right-sum}=-\infty$
        \li $sum=0$
        \li \For $j\gets mid+1$ \To $high$
        \li \Do $sum=sum+A[j]$
        \li \If $sum>\id{right-sum}$
        \li \Then $\id{right-sum}=sum$
        \li $\id{max-right}=j$\End\End
        \li \Return $(\id{max-left},\id{max-right},\id{left-sum}+\id{right-sum})$
      \end{codebox}}
}\\
\vspace{-0.5cm}
Complexité: $\Theta(n)$~\hfill\includegraphics[width=6cm]{Figures/06-maxsubarray-cross-algo.pdf}
\end{frame}

\begin{frame}{$\proc{Max-subarray}$}

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max-subarray}(A,low,high)$}
        \li \If $high\isequal low$
        \li \Then \Return $(low,high,A[low])$
        \li \Else $mid=\lfloor (low+high)/2 \rfloor$
        \li $(\id{left-low},\id{left-high},\id{left-sum})=\proc{Max-subarray}(A,low,mid)$
        \li $(\id{right-low},\id{right-high},\id{right-sum})=\proc{Max-subarray}(A,mid+1,high)$
        \li $(\id{cross-low},\id{cross-high},\id{cross-sum})=$
        \li \Indent $\proc{Max-crossing-subarray}(A,low,mid,high)$
        \li \If $\id{left-sum}\geq \id{right-sum}$ and $\id{left-sum}\geq \id{cross-sum}$
        \li \Then \Return $(\id{left-low},\id{left-high},\id{left-sum})$
        \li \ElseIf $\id{right-sum}\geq \id{right-sum}$ and $\id{right-sum}\geq \id{cross-sum}$
        \li \Then \Return $(\id{right-low},\id{right-high},\id{right-sum})$
        \li \Else \Return $(\id{cross-low},\id{cross-high},\id{cross-sum})$
      \end{codebox}}
}
\end{center}

\end{frame}

\begin{frame}{Analyse}

\begin{itemize}
\item Si on suppose que $n$ est un multiple de 2, le nombre d'opérations $T(n)$ est donné par:
\[
T(n) = \left\{
\begin{array}{ll}
 c_1 & \mbox{si }n=1\\
2 T(n/2)+c_2 n & \mbox{sinon}
\end{array}
\right.
\]
\item Même complexité que le tri par fusion $\Rightarrow$ $\Theta(n\log n)$
\item Peut-on faire mieux ? On verra plus loin que oui
\end{itemize}

\end{frame}

\begin{frame}{Diviser pour régner: résumé}

\begin{itemize}
\item Mène à des algorithmes très efficaces
\item Pas toujours applicable mais quand même très utile

\bigskip

\item Applications:
\begin{itemize}
\item Tris optimaux
\item Recherche binaire
\item Problème de sélection
\item Trouver la paire de points les plus proches
\item Recherche de l'enveloppe convexe (convex-hull)
\item Multiplication de matrice (méthode de Strassens)
\item \ldots
\end{itemize}
\end{itemize}

\end{frame}

\section{Programmation dynamique}

\begin{frame}{Méthodes de résolution de problèmes}

Quelques approches génériques pour aborder la résolution d'un problème:
\begin{itemize}
\item \alert{Approche par force brute:} résoudre directement le problème, à partir de sa définition ou par une recherche exhaustive
\item \alert{Diviser pour régner:} diviser le problème en sous-problèmes, les résoudre, fusionner les solutions pour obtenir une solution au problème original
\item \alert{Programmation dynamique:} obtenir la solution optimale à un problème en combinant des solutions optimales à des sous-problèmes similaires plus petits et se chevauchant
\semitransp{\item {Approche gloutonne:} construire la solution incrémentalement, en optimisant de manière aveugle un critère local}
\end{itemize}

\end{frame}

\begin{frame}{Plan}

\tableofcontents[currentsection,hideothersubsections]

\end{frame}

\subsection{Exemple 1: découpage de tiges d'acier}

\begin{frame}{Exemple 1: découpage de tiges d'acier}

\bigskip

\centerline{\includegraphics[width=4cm]{Figures/06-steelrod.pdf}}

\bigskip

\begin{itemize}
\item Soit une tige d'acier qu'on découpe pour la vendre morceau par morceau
\item La découpe ne peut se faire que par nombre entier de centimètres
\item Le prix de vente d'une tige dépend (non linéairement) de sa longueur
\item On veut déterminer le revenu maximum qu'on peut attendre de la
  vente d'une tige de $n$ centimètres
\item Problème algorithmique:
\begin{itemize}
\item Entrée: une longueur $n>0$ et une table de prix $p_i$, pour $i=1,2,\ldots,n$
\item Sortie: le revenu maximum qu'on peut obtenir pour des tiges de longueur $n$
\end{itemize}
\end{itemize}
\note{Pourquoi est-ce que je mets non linéairement ? Parce que la dépendance est linéaire, peu importe la manière dont on coupe la tige}
\end{frame}

\begin{frame}{Illustration}
\begin{itemize}
\item Soit la table de prix:
\bigskip

\begin{center}\small
\begin{tabular}{l|llllllllll}
Longueur $i$ & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
\hline
Prix $p_i$ & 1 & 5 & 8 & 9 & 10 & 17 & 17 & 20 & 24 & 30\\
\end{tabular}
\end{center}

\bigskip

\item Découpes possibles d'une tige de longueur $n=4$

\bigskip

\centerline{\includegraphics[width=10cm]{Figures/06-rodcutting.pdf}}

\bigskip

\item Meilleur revenu: découpage en 2 tiges de 2 centimètres, revenu de 10
\end{itemize}
\end{frame}

\begin{frame}{Approche par force brute}

\begin{itemize}
\item Enumérer toutes les découpes, calculer leur revenu, déterminer le revenu maximum
\item Complexité: exponentielle en $n$:
\begin{itemize}
\item Il y a $2^{n-1}$ manières de découper une tige de longueur $n$ (on peut couper ou non après chacun des $n-1$ premiers centimètres)
\item Plusieurs découpes sont équivalentes (1+1+2 et 1+2+1 par
  exemple) mais même en prenant cela en compte, le nombre de découpes
  reste exponentiel
\end{itemize}
\item Infaisable pour $n$ un peu grand
\end{itemize}

\note{dessiner un arbre avec toutes les possibilités. Dire que le nombre de feuille est $2^{n-1}$.}
\end{frame}

\begin{frame}{Idée}
\begin{itemize}
\item Soit $r_i$ le revenu maximum pour une tige de longueur $i$
\item Peut-on formuler $r_n$ de manière récursive ?
\item Déterminons $r_i$ pour notre exemple:
\begin{center}
\footnotesize
\begin{tabular}{l|cl}
i & $r_i$ & solution optimale\\
\hline
1 & 1 & 1 (pas de découpe)\\
2 & 5 & 2 (pas de découpe)\\
3 & 8 & 3 (pas de découpe)\\
4 & 10 & 2+2\\
5 & 13 & 2+3\\
6 & 17 & 6 (pas de découpe)\\
7 & 18 & 1+6 ou 2+2+3\\
8 & 22 & 2+6
\ldots\\
\end{tabular}
\end{center}
\end{itemize}

\note{Dans le cas $n=4$, on doit comparer: 4, 1+3, 2+2, 3+1, 1+1+2, 1+2+1, 2+1+1, 1+1+1+1\\

Le max de 1+3, 1+2+1, 1+1+2, 1+1+1+1 est égal au prix de 1 plus $r_3$}
\end{frame}

\begin{frame}{Formulation récursive de $r_n$: version naïve}
\begin{itemize}
\item $r_n$ peut être calculé comme le maximum de:
\begin{itemize}
\item $p_n$: le prix sans découpe
\item $r_1+r_{n-1}$: le revenu max pour une tige de 1 et une tige de $n-1$
\item $r_2+r_{n-2}$: le revenu max  pour une tige de 2 et une tige de $n-2$
\item \ldots
\item $r_{n-1}+r_1$.
\end{itemize}
\item C'est-à-dire $$r_n=\max(p_n,r_1+r_{n-1},r_2+r_{n-2},\ldots,r_{n-1}+r_1)$$
\end{itemize}
\end{frame}

\begin{frame}{Formulation récursive de $r_n$: version simplifiée}

\begin{itemize}
\item Toute solution optimale a un découpe la plus à gauche
\item On peut calculer $r_n$ en considérant toutes les tailles pour la première découpe et en combinant avec le découpage optimal pour la partie à droite
\item Pour chaque cas, on n'a donc qu'à résoudre un seul sous-problème (au lieu de deux), celui du découpage de la partie droite
\item En supposant $r_0=0$, on obtient ainsi:
$$r_n=\max_{1\leq i \leq n} (p_i+r_{n-i})$$
\end{itemize}

\note{Faire un dessin au tableau avec la partie gauche de toutes les tailles}

\end{frame}

\begin{frame}{Implémentation récursive directe}

\begin{itemize}
\item La formule récursive peut être implémentée directement

\bigskip

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Cut-rod}(p,n)$}
        \li \If $n\isequal 0$
        \li \Then \Return 0\End
        \li $q=-\infty$
        \li \For $i\gets 1$ \To $n$
        \li \Do $q\gets \max(q,p[i]+\proc{Cut-Rod}(p,n-i))$\End
        \li \Return $q$
      \end{codebox}}
}
\end{center}
(p est un tableau de taille $n$ contenant les prix des tiges de tailles 1 à $n$)
\bigskip
\item Complexité ?
\end{itemize}

\end{frame}

\begin{frame}{Implémentation récursive directe: analyse}

\begin{itemize}
\item L'algorithme est extrêmement inefficace à cause des appels récursifs redondants
\item Exemple: arbre des appels récursifs pour le calcul de $r_4$

\centerline{\includegraphics[width=5cm]{Figures/06-rodcutting-recursiontree.pdf}}

%% \item Le sous-problème de taille 3 est résolu 1 fois, le sous-problème de taille 2 est résolu 2 fois, le sous-problème de taille 1 est résolu 4 fois, le sous-problème de taille 0 est résolu 8 fois
\item En général, le nombre de n\oe uds $T(n)$ de l'arbre est $2^n$.\\
{\small Preuve par induction:
\begin{itemize}
\item Cas de base: $T(0)=1$
\item Cas inductif: $$T(n)=1+\sum_{j=0}^{n-1} T(j)=1+\sum_{j=0}^{n-1} 2^j=1+2^n-1=2^n$$
\end{itemize}}
\item Complexité de l'algorithme est exponentielle en $n$
\end{itemize}
\note{Compter sur le graphe: nombre de 3, nombre de 1, nombre de 2}
\end{frame}

\begin{frame}{Solution par programmation dynamique}

\begin{itemize}
\item Solution: plutôt que de résoudre les mêmes sous-problèmes plusieurs fois,
  s'arranger pour ne les résoudre chacun qu'une seule fois
\item Comment ? En sauvegardant les solutions dans une table et en se
  référant à la table à chaque demande de résolution d'un
  sous-problème déjà rencontré
\item On échange du temps de calcul contre de la mémoire
\item Permet de transformer une solution en temps exponentiel en une solution en temps polynomial
\item Deux implémentations possibles:
\begin{itemize}
\item descendante (top-down) avec \alert{mémoization}
\item ascendante (bottom-up)
\end{itemize}

\end{itemize}

\end{frame}

\begin{frame}{Approche descendante avec mémoization}

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Memoized-Cut-rod}(p,n)$}
        \li Let $r[0\twodots n]$ be a new array
        \li \For $i\gets 1$ \To $n$
        \li \Do $r[i]\gets -\infty$\End
        \li \Return $\proc{memoized-cut-rod-aux}(p,n,r)$
      \end{codebox}}

\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Memoized-Cut-rod-aux}(p,n,r)$}
        \li \If $r[n]\geq 0$
        \li \Then \Return $r[n]$\End
        \li \If $n\isequal 0$
        \li \Then $q=0$
        \li \Else $q=-\infty$
        \li \For $i\gets 1$ \To $n$
        \li \Do $q=\max(q,p[i]+\proc{memoized-cut-rod-aux}(p,n-i,r))$\End\End
        \li $r[n]=q$
        \li \Return $q$
      \end{codebox}}
}
\end{center}

(Attention: suppose que le tableau est passé par pointeur)

\note{Dire qu'ils doivent bien réfléchir pour être sûr de comprendre\\

\bigskip

{\color{red} Montrer sur l'arbre de récursion comme ça fonctionne !!!}
}
\end{frame}

\begin{frame}{Approche ascendante}

Principe: résoudre les sous-problèmes par taille en commençant d'abord par les plus petits

\bigskip

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Bottom-up-Cut-rod}(p,n)$}
        \li Let $r[0\twodots n]$ be a new array
        \li $r[0]=0$
        \li \For $j\gets 1$ \To $n$
        \li \Do $q=-\infty$
        \li \For  $i\gets 1$ \To $j$
        \li \Do $q=\max(q,p[i]+r[j-i])$\End
        \li $r[j]=q$\End
        \li \Return $r[n]$
      \end{codebox}}
}
\end{center}

\end{frame}

\begin{frame}{Programmation dynamique: analyse}

\begin{itemize}
\item Solution ascendante est clairement $\Theta(n^2)$ (deux boucles imbriquées)
\item Solution descendante est également $\Theta(n^2)$
\begin{itemize}
\item Chaque sous-problème est résolu une et une seule fois
\item La résolution d'un sous-problème passe par une boucle à $n$ itérations
\end{itemize}
\item Graphes des sous-problèmes:

\centerline{\includegraphics[width=1.5cm]{Figures/06-subproblems-graph.pdf}}

(une flèche de $x$ à $y$ indique que la résolution de $x$ dépend de la résolution de $y$)
\end{itemize}

\note{On voit bien que c'est $n^2$ sur ce graphe\\

On ne doit plus suivre les flèches. Chaque flèche correspond à un lookup dans une table
}

\end{frame}

\begin{frame}{Reconstruction de la solution}
\begin{itemize}
\item Fonction $\proc{Bottom-up-Cut-rod}$ calcule le revenu maximum mais ne donne pas directement la découpe correspondant à ce revenu
\item On peut étendre l'approche ascendante pour enregistrer également la solution dans une autre table
\end{itemize}

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Extended-Bottom-up-Cut-rod}(p,n)$}
        \li Let $r[0\twodots n]$ and $s[0\twodots n]$ be new arrays
        \li $r[0]=0$
        \li \For $j\gets 1$ \To $n$
        \li \Do $q=-\infty$
        \li \For  $i\gets 1$ \To $j$
        \li \Do \If $q<p[i]+r[j-i]$
        \li \Then $q=p[i]+r[j-i]$
        \li $s[j]=i$\End\End
        \li $r[j]=q$\End
        \li \Return $r$ and $s$
      \end{codebox}}
}
\end{center}

\begin{itemize}
\item $s[j]$ contient la coupure la plus à gauche d'une solution
  optimale au problème de taille $j$
\end{itemize}

\note{Si on met à jour le max dans q, c'est que c'est mieux de couper d'abord en i et puis couper le reste de manière optimale}
\end{frame}

\begin{frame}{Reconstruction de la solution}
\begin{itemize}
\item Pour afficher la solution, on doit ``remonter'' dans $s$
\bigskip

\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Print-cut-rod-solution}(p,n)$}
        \li $(r,s)=\proc{Extended-bottom-up-cut-rod}(p,n)$
        \li \While $n>0$
        \li \Do $\proc{print}$ $s[n]$
        \li $n=n-s[n]$\End
      \end{codebox}}
}
\end{center}

\bigskip

\item Exemple:
\bigskip
\begin{center}\small
\begin{tabular}{c|llllllllll}
$i$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
\hline
$p[i]$ & 0 & 1 & 5 & 8 & 9 & 10 & 17 & 17 & 20 \\
$r[i]$ & 0 &  1 & 5 & 8 & 10 & 13 & 17 & 18 & 22\\
$s[i]$ & 0 & 1 & 2 & 3 & 2 & 2 & 6 & 1 & 2\\
\end{tabular}
\end{center}
\bigskip
$$\proc{print-cut-rod-solution}(p,8) \Rightarrow \mbox{"2 6"}$$

\end{itemize}
\end{frame}

\begin{frame}{Programmation dynamique: généralités}
\begin{itemize}
\item La programmation dynamique s'applique aux problèmes d'\alert{optimisation} qui peuvent se décomposer en sous-problèmes de même nature, et qui possèdent les deux propriétés suivantes:
\begin{itemize}
\item \alert{Sous-structure optimale:} on peut calculer la solution d'un problème de taille $n$ à partir de la solution de sous-problèmes de taille inférieure
\item \alert{Chevauchement des sous-problèmes:} Certains sous-problèmes distincts partagent une partie de leurs sous-problèmes
\end{itemize}
\item Implémentation directe récursive donne une solution de complexité exponentielle
\item Sauvegarde des solutions aux sous-problèmes donne une complexité linéaire dans le nombre d'arcs et de sommets du graphe des sous-problèmes
\end{itemize}
\end{frame}

\subsection{Exemple 2: Fibonacci}

\begin{frame}{Exemple 2: Fibonacci}

\begin{itemize}
\item La fonction $\proc{Fibonacci-Iter}$ vue au début du cours est un
  exemple de programmation dynamique (ascendante)
\end{itemize}

\begin{columns}
\begin{column}{5cm}
\begin{center}\footnotesize
\fcolorbox{white}{Lightgray}{
\begin{codebox}
\Procname{$\proc{Fibonacci-Iter}(n)$}
\li \If $n \leq 1$
\li \Then \Return n \End
\li \Else
\li \Then $pprev\gets 0$
\li $prev\gets 1$
\li \For $i\gets 2 \To n$
\li \Do $f\gets prev+pprev$
\li $pprev\gets prev$
\li $prev\gets f$\End
\li \Return f \End
\end{codebox}
}
\end{center}
\end{column}
\begin{column}{5cm}
\centerline{\includegraphics[width=0.8cm]{Figures/06-subproblem-graph-fibonacci.pdf}}
\end{column}
\end{columns}

\begin{itemize}
\item On peut se contenter de ne stocker que les deux dernières valeurs
\item Complexité $\Theta(n)$ (graphe contient $n+1$ n\oe uds et $2n-2$ arcs)
\end{itemize}
{\it (Exercice: écrivez la version descendante avec mémoization)}

\end{frame}

\begin{frame}{Interlude: Fibonacci en $\Theta(\log n)$}
\begin{itemize}
\item Peut-on faire mieux que $\Theta(n)$ pour Fibonacci ? Oui !
\item Propriété: {\small $$\begin{pmatrix} F_{n+1} &F_n\\F_n&F_{n-1}\\\end{pmatrix}=\begin{pmatrix} 1&1\\1&0\\\end{pmatrix}^n$$}
\item Preuve par induction:
\begin{itemize}
\item Cas de base ($n=1$): ok puisque $F_0=0$, $F_1=1$, et $F_2=1$
\item Cas inductif ($n\geq 2$):
{\small
\begin{eqnarray*}
\begin{pmatrix} F_{n+1} &F_n\\F_n&F_{n-1}\\\end{pmatrix} & = & \begin{pmatrix} F_{n} &F_{n-1}\\F_{n-1}&F_{n-2}\\\end{pmatrix} \cdot \begin{pmatrix} 1&1\\1&0\\\end{pmatrix}\\
& =&  \begin{pmatrix} 1&1\\1&0\\\end{pmatrix}^{n-1} \cdot \begin{pmatrix} 1&1\\1&0\\\end{pmatrix}\\
& = & \begin{pmatrix} 1&1\\1&0\\\end{pmatrix}^{n}
\end{eqnarray*}}\qed
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Interlude: Fibonacci en $\Theta(\log n)$}
\begin{itemize}
\item Approche par force brute pour le calcul de $\begin{pmatrix} 1&1\\1&0\\\end{pmatrix}^n$: $\Theta(n)$
\item Idée: utiliser le diviser-pour-régner pour le calcul de $a^n$
\[
a^n = \left\{
\begin{array}{ll}
a^{n/2} \cdot a^{n/2}  & \mbox{si }n\mbox{ est pair}\\
a^{(n-1)/2}\cdot a^{(n-1)/2} \cdot a & \mbox{si }n\mbox{ est impair}
\end{array}
\right.
\]
\item Complexité: $\Theta(\log n)$ (comme la recherche binaire)
\end{itemize}

\bigskip

{\it (Exercice: implémenter l'algorithme)}
\end{frame}

\subsection{Exemple 3: sous-séquence de somme maximale}

\begin{frame}{Exemple 3: sous-séquence maximale}
%(ou la revenge de la programmation dynamique)

\bigskip

%Algorithme de Kadane pour la recherche d'un sous-séquence de somme maximale dans un tableau

\begin{columns}
\begin{column}{7cm}
\begin{center}
{\footnotesize
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Max-subarray-linear}(A)$}
        \li Let $m[1\twodots n]$ be a new array
        \li $\id{max-so-far}\gets A[1]$
        \li $m[1]=A[1]$
        \li \For $i\gets 2$ \To $A.length$
        \li \Do \If $m[i-1]>0$
        \li \Then $m[i]=m[i-1]+A[i]$
        \li \Else $m[i]=A[i]$\End
        \li \If $m[i]>\id{max-so-far}$
        \li \Then $\id{max-so-far}=m[i]$\End\End 
        \li \Return $\id{max-so-far}$
      \end{codebox}}
}
\end{center}
\end{column}
\begin{column}{3cm}
\centerline{\includegraphics[width=0.7cm]{Figures/06-subproblems-graph-max.pdf}}
\end{column}
\end{columns}

\bigskip

\begin{itemize}
\item Complexité: $\Theta(n)$ (diviser pour régner: $\Theta(n\log n)$)
\item $m[i]$ est la somme de la sous-séquence maximale qui se termine en $i$
\item L'algorithme calcule $m[i]$ à partir de $m[i-1]$
\item Forme de programmation dynamique ascendante (très simple)
\end{itemize}

{\it\small (Exercice: ajouter le calcul des bornes d'un sous-tableau solution, remplacer le tableau $m$ par une seule variable)}

\end{frame}

\subsection{Exemple 4: plus longue sous-séquence commune}

\begin{frame}{Exemple 4: plus longue sous-séquence commune}

\begin{itemize}
\item Définition: Une \alert{sous-séquence} (non contiguë) d'une séquence $\langle x_1,\ldots,x_m\rangle$ est une séquence $\langle x_{i_1}, x_{i_2}, \ldots, x_{i_k}\rangle$, où $1\leq i_1 < i_2 < \ldots <i_k\leq m$.
\item Problème: Etant donné 2 séquences, $X=\langle
  x_1,\ldots,x_m\rangle$ et $Y=\langle y_1,\ldots,y_n\rangle$, trouver une plus grande sous-séquence commune aux deux séquences
\item Exemples:
\centerline{\includegraphics[width=8cm]{Figures/06-exemples-lcs.pdf}}
\end{itemize}
\end{frame}

\begin{frame}{Solution par force brute}

\begin{itemize}
\item On énumère toutes les sous-séquences de la séquence la plus courte
\item Pour chacune d'elles, on vérifie si c'est une sous-séquence de la séquence la plus longue

\bigskip

\item Complexité: $\Theta(n\cdot 2^m)$ (en supposant que $n<m$)
\begin{itemize}
\item $2^m$ sous-séquences possibles dans une séquence de longueur $m$
\item Vérification de l'occurence d'une sous-séquence dans une
  séquence de longueur $n$ en $\Theta(n)$

\bigskip
~\hfill{\it (Exercice:
    implémenter la vérification)}
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Solution par programmation dynamique}

Propriété de sous-structure:
\begin{itemize}
\item Soit $X_i=\langle x_1,\ldots,x_i\rangle$ un préfixe de $X$ et
  $Y_i=\langle y_1,\ldots,y_i\rangle$ un préfixe de $Y$
\item Soit $Z=\langle z_1,\ldots,z_k\rangle$ une plus longue sous-séquence commune de $X$ et $Y$
\item Les propriétés suivantes sont vérifiées:
\begin{itemize}
\item Si $x_m=y_n$, alors $z_k=x_m=y_n$ et $Z_{k-1}$ est une plus
  longue sous-séquence commune de $X_{m-1}$ et $Y_{n-1}$.
\item Si $x_m\neq y_n$, alors $z_k\neq x_m\Rightarrow Z$ est une plus
  longue sous-séquence commune à $X_{m-1}$ et $Y$
\item Si $x_m\neq y_n$, alors $z_k\neq y_n\Rightarrow$ $Z$ est une
  plus longue sous-séquence commune à $X$ et $Y_{n-1}$
\end{itemize}
\end{itemize}
\alert{$\Rightarrow$} Une plus longue sous-séquence commune de deux séquences a pour préfixe
une plus longue sous-séquence des préfixes des deux séquences.

\end{frame}

\begin{frame}{Solution par programmation dynamique}
\begin{itemize}
\item Soit $c[i,j]$ la longueur d'une plus longue sous-séquence de $X_i$ et $Y_j$.
\item Formulation récursive:
\[c[i,j]=\left\{
\begin{array}{ll}
0 & \mbox{ si } i=0\mbox{ ou }j=0,\\
c[i-1,j-1]+1 & \mbox{ si }i,j>0\mbox{ et }x_i=y_j,\\
\max(c[i-1,j],c[i,j-1]) & \mbox{ si }i,j>0\mbox{ et }x_i\neq y_j,\\
\end{array}
\right.
\]
\item Graphe des sous-problèmes:
\end{itemize}

\centerline{\includegraphics[width=4cm]{Figures/06-lcs-subproblemsgraph.pdf}}

\note{Leur faire remplir la table. En mettant un exemple: amputation et spanking}

\end{frame}

\begin{frame}{Implémentation (ascendante)}

{\small
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{LCS-Length}(X,Y,m,n)$}
        \li Let $c[0\twodots m, 0\twodots n]$ be a new table
        \li \For $i=1$ \To $m$
        \li \Do c[i,0]=0 \End
        \li \For $j=0$ \To $n$
        \li \Do c[0,j]=0 \End
        \li \For $i=1$ \To $m$
        \li \Do \For $j=1$ \To $n$
        \li \Do \If $x_i\isequal y_j$
        \li \Then $c[i,j]=c[i-1,j-1]+1$
        \li \ElseIf  $c[i-1,j]\geq c[i,j-1]$
        \li \Then $c[i,j]=c[i-1,j]$
        \li \Else $c[i,j]=c[i,j-1]$\End\End\End
        \li \Return $c$
      \end{codebox}}
\end{center}
}

\bigskip

Complexité: $\Theta(m\cdot n)$

\end{frame}

\begin{frame}{Illustration}
$amputation$ versus $spanking$

\bigskip

\centerline{\includegraphics[width=8cm]{Figures/06-lcs-algoexemple.pdf}}

\end{frame}

\begin{frame}{Trouver la plus longue sous-séquence}

\begin{columns}
\begin{column}{5cm}
{\scriptsize
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{LCS-Length}(X,Y,m,n)$}
        \li Let $c[0\twodots m, 0\twodots n]$ be a new table
        \li {\color{red} Let $b[1\twodots m,1\twodots n]$ be a new table}
        \li \For $i=1$ \To $m$
        \li \Do c[i,0]=0 \End
        \li \For $j=0$ \To $n$
        \li \Do c[0,j]=0 \End
        \li \For $i=1$ \To $m$
        \li \Do \For $j=1$ \To $n$
        \li \Do \If $x_i\isequal y_j$
        \li \Then $c[i,j]=c[i-1,j-1]+1$
        \li {\color{red} $b[i,j]="\nwarrow"$}
        \li \ElseIf  $c[i-1,j]\geq c[i,j-1]$
        \li \Then $c[i,j]=c[i-1,j]$
        \li {\color{red} $b[i,j]="\uparrow"$}
        \li \Else $c[i,j]=c[i,j-1]$
        \li {\color{red} $b[i,j]="\leftarrow"$}\End\End\End        
        \li \Return $c$ {\color{red} and $b$}
      \end{codebox}}
\end{center}
}
\end{column}
\begin{column}{5cm}
{\scriptsize
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Print-LCS}(b,X,i,j)$}
        \li \If $i\isequal 0$ or $j\isequal 0$
        \li \Then \Return\End
        \li \If $b[i,j]\isequal"\nwarrow"$
        \li \Then $\proc{Print-LCS}(b,X,i-1,j-1)$
        \li print $x_i$\End
        \li \ElseIf $b[i,j]\isequal "\uparrow"$
        \li \Then $\proc{Print-LCS}(b,X,i-1,j)$
        \li \Else $\proc{Print-LCS}(b,X,i,j-1)$
      \end{codebox}}
\end{center}
}
\end{column}
\end{columns}

\end{frame}

\subsection{Exemple 5: le problème 0-1 du sac à dos}

\begin{frame}{Exemple 5: le problème du sac à dos (knapsack)}

Problème:
\begin{itemize}
\item Un voleur se rend dans un musée pour commettre un méfait avec un
  sac à dos pouvant contenir $W$ kg.
\item Le musée comprend $n$ \oe uvres d'art, chacune de poids $p_i$ et
  de prix $v_i$ ($i=1,\ldots,n$)
\item Le problème pour le voleur est de déterminer une sélection
  d'objets de valeur totale maximale et n'excédant pas le poids total
  admissible dans le sac à dos.
\end{itemize}

\bigskip

Formellement:
\begin{itemize}
\item Soit un ensemble $S$ de $n$ objets de poids $p_i>0$ et de valeurs $v_i>0$
\item Trouver $x_1, x_2, \ldots, x_n \in \{0,1\}$ tels que:
\begin{itemize}
\item $\sum_{i=1}^n x_i\cdot p_i\leq W$, et
\item $\sum_{i=1}^n x_i\cdot v_i$ est maximal.
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Exemple}

\begin{columns}
\begin{column}{5cm}

Capacité du sac à dos:

$$W=11$$
\end{column}
\begin{column}{5cm}
\begin{center}
\begin{tabular}{ccc}
$i$ & $v_i$ & $p_i$\\
\hline
1 & 1 & 1\\
2 & 6 & 2\\
3 & 18 & 5\\
4 & 22 & 6\\
5 & 28 & 7
\end{tabular}
\end{center}
\end{column}
\end{columns}

\bigskip

Exemple:
\begin{itemize}
\item $\{5,2,1\}$ a un poids de 10 et une valeur de 35
\item $\{3,4\}$ a un poids de 11 et une valeur de 40
\end{itemize}

\end{frame}

\begin{frame}{Approche par force brute}

\begin{itemize}
\item Recherche exhaustive: on énumère tous les sous-ensembles de $S$, et on calcule leur poids et leur valeur
\item Complexité en temps: $O(n 2^n)$
\item Améliorations:
\begin{itemize}
\item Ne tester que les sous-ensembles de $W/p_{min}$ objets où
  $p_{min}$ est la taille minimale
\item Tester les objets par ordre croissant et s'arrêter dès que l'un
  d'entre eux n'entre plus
\end{itemize}
\item Diminue la constante mais la complexité reste la même
\end{itemize}

\end{frame}

\begin{frame}{Approche par programmation dynamique}

\begin{itemize}
\item Définition: soit $M(k,w)$, $0\leq k\leq n$ et $0\leq w\leq W$, le bénéfice
  maximum qu'on peut obtenir avec les objets 1,\ldots,$k$ de $S$ et
  un sac à dos de charge maximale $w$\\
{\it (On suppose que les poids $p_i$ et $W$ sont entiers)}
\item Deux cas:
\begin{itemize}
\item On ne sélectionne pas l'objet $k$: $M(k,w)$ est le bénéfice maximum
  en sélectionnant parmi les $k-1$ premiers objets avec
  comme limite $w$ ($M(k-1,w)$)
\item On sélectionne l'objet $k$: $M(k,w)$ est la valeur de l'objet
  $k$ plus le bénéfice maximum en sélectionnant parmi les $k-1$
  premiers objets avec la limite $w-p_k$
\end{itemize}
\end{itemize}

\[M(k,w)=\left\{\begin{array}{ll}
0 & \mbox{ si }k=0\\
M(k-1,w) & \mbox{ si } p_k>w\\
\max\{M(k-1,w),v_k+M(k-1,w-p_k)\} &  \mbox{ sinon}
\end{array}
\right.
\]
\label{part6:knapsack}
\end{frame}

\begin{frame}{Implementation}

{\small
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{KnapSack}(p,v,n,W)$}
        \li Let $M[0\twodots n, 0\twodots W]$ be a new table
        \li \For $w=0$ \To $W$
        \li \Do M[0,w]=0 \End
        \li \For $k=1$ \To $n$
        \li \Do $M[k,0]=0$ \End
        \li \For $k=1$ \To $n$
        \li \Do \For $w=1$ \To $W$
        \li \Do \If $p[k]>w$
        \li \Then $M[k,w]=M[k-1,w]$
        \li \ElseIf $M[k-1,w]>v[k]+M[k-1,w-p[k]]$
        \li     \Do $M[k,w]=M[k-1,w]$
        \li \Else $M[k,w]=v[k]+M[i-1,w-p[k]]$
        \End\End\End
        \li \Return $M[n,W]$
      \end{codebox}}
\end{center}
}


\end{frame}

\begin{frame}{Exemple}

\begin{tabular}{c|cccccccccccc}
$M$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11\\
\hline
$\emptyset$ &     {\color{red}0} & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
$\{1\}$ &         {\color{red}0} & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
$\{1,2\}$ &       {\color{red}0} & 1 & 6 & 7 & 7 & 7 & 7 & 7 & 7 & 7 & 7 & 7\\
$\{1,2,3\}$ &     0 & 1 & 6 & 7 & 7 & {\color{red}18}& 19& 24& 25& 25& 25& 25\\
$\{1,2,3,4\}$ &   0 & 1 & 6 & 7 & 7 & 18& 22& 24& 28& 29& 29& {\color{red}40}\\
$\{1,2,3,4,5\}$ & 0 & 1 & 6 & 7 & 7 & 18& 22& 28& 29& 34& 35& {\color{red}40}\\
\end{tabular}

\begin{columns}
\begin{column}{5cm}
Solution optimale: $\{4, 3\}$\\
Bénéfice: $22+18=40$
\end{column}
\begin{column}{5cm}
\begin{center}
$W=11$~~~~
\begin{tabular}{ccc}
$i$ & $v_i$ & $p_i$\\
\hline
1 & 1 & 1\\
2 & 6 & 2\\
3 & 18 & 5\\
4 & 22 & 6\\
5 & 28 & 7
\end{tabular}
\end{center}
\end{column}
\end{columns}

\end{frame}


\begin{frame}{Récupération des $x_i$}

En remontant dans le tableau $M$:

{\small
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{KnapSack}(p,v,n,W)$}
        \li \Comment Compute M
        \li \ldots
        \li \Comment Retrieve solution
        \li Let $x[1\twodots n]$ be a new table
        \li $w=W$
        \li \For $k=n$ \Downto $1$
        \li \Do \If $M[k,w]\isequal M[k-1,w]$
        \li    \Then $x[k]=0$
        \li \Else
        \li $x[k]=1$
        \li $w=w-p[k]$ \End\End
        \li \Return $x$
      \end{codebox}}
\end{center}
}

\end{frame}

\begin{frame}{Complexité}

\begin{itemize}
\item Complexité en temps et en espace: $\Theta(n W)$
\begin{itemize}
\item Remplissage de la matrice $M$: $\Theta(n W)$
\item Recherche de la solution: $\Theta(n)$
\end{itemize}
{\it (Exercice: proposez une version $\Theta(n+W)$ en espace)}

\bigskip

\item Note: L'algorithme n'est en fait pas polynomial en fonction de la taille de l'entrée
\begin{itemize}
\item Si $W$ nécessite $n_w$ bits pour son codage, la complexité est $\Theta(n 2^{n_w})$
\item Comme pour le voyageur de commerce, on n'a pas encore trouvé d'algorithme polynomial pour le problème du sac à dos (et il y a peu de chance qu'on y arrive)
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Programmation dynamique: résumé}

Grandes étapes:
\begin{itemize}
\item Caractériser la structure du problème
\item Définir de manière récursive la \alert{valeur} de la solution optimale
\item Calculer les valeurs de la solution optimale (c'est-à-dire remplir un tableau)
\item Reconstruire la (une) solution optimale à partir de l'information calculée (``bottom-up'')
\end{itemize}
\bigskip

Applications:
\begin{itemize}
\item Command unix diff (comparaison de fichiers)
\item Algorithme de Viterbi (reconnaissance vocale)
\item Alignement de séquences d'ADN (Smith-Waterman)
\item Plus court chemin dans un graphe (Bellman-Ford)
\item Compilateurs (analyse syntaxique et optimisation du code)
\item \ldots
\end{itemize}

\end{frame}

\begin{frame}{Programmation dynamique versus diviser-pour-régner}
\begin{itemize}
\item L'approche Diviser-pour-régner décompose aussi le problème en sous-problèmes
\item Mais ces sous-problèmes sont significativement plus petits que le problème de départ ($n \rightarrow n/2$)
\begin{itemize}
\item Alors que la programmation dynamique réduit généralement un problème de taille $n$ en sous-problèmes de taille $n-1$
\end{itemize}
\item Et ces sous-problèmes sont indépendants
\begin{itemize}
\item Alors qu'en programmation dynamique, ils se recouvrent
\end{itemize}
\item Pour ces deux raisons, la récursivité ne fonctionne pas pour la programmation dynamique
\end{itemize}

\end{frame}

\section{Algorithmes gloutons}

\begin{frame}{Méthodes de résolution de problèmes}

Quelques approches génériques pour aborder la résolution d'un problème:
\begin{itemize}
\item \alert{Approche par force brute:} résoudre directement le problème, à partir de sa définition ou par une recherche exhaustive
\item \alert{Diviser pour régner:} diviser le problème en sous-problèmes, les résoudre, fusionner les solutions pour obtenir une solution au problème original
\item \alert{Programmation dynamique:} obtenir la solution optimale à un problème en combinant des solutions optimales à des sous-problèmes similaires plus petits et se chevauchant
\item \alert{Approche gloutonne:} construire la solution incrémentalement, en optimisant de manière aveugle un critère local
\end{itemize}

\end{frame}

\begin{frame}{Plan}

\tableofcontents[currentsection,hideothersubsections]

\end{frame}

\begin{frame}{Algorithme glouton (greedy)}

\begin{itemize}
\item Utilisé pour résoudre des problèmes d'optimisation (comme la programmation dynamique)
\item Idée principale:
\begin{itemize}
\item Quand on a un choix local à faire, faire le choix (glouton) qui semble le meilleur tout de suite (et ne jamais le remettre en question)
\end{itemize}
\item Pour que l'approche fonctionne, le problème doit satisfaire deux propriétés:
\begin{itemize}
\item \alert{Propriété des choix gloutons optimaux}: On peut toujours arriver
  à une solution optimale en faisant un choix localement optimal
\item \alert{Propriété de sous-structure optimale}: Une solution optimale du problème est composée de solutions optimales à des sous-problèmes
\end{itemize}
\item Même si ces propriétés ne sont pas satisfaites, l'approche
  gloutonne peut parfois fournir une approximation intéressante au problème
\item Parfois, il est possible de caractériser la distance de la
  solution gloutonne à la solution optimale
\end{itemize}

\end{frame}

%Change de pieces de Benard Boigelot\\

%Activity scheduling\\

%Code Huffman\\

%fractionnal Knapsack

\subsection{Exemple 1: rendre la monnaie}

\begin{frame}{Exemple 1: rendre la monnaie}

\begin{itemize}
\item Objectif: Etant donné des pièces de 1, 2, 5, 10, et 20
  cents, trouver une méthode pour rembourser une somme de $x$ cents en
  utilisant le moins de pièces possible.
\item Exemple: 34 cents:
\begin{itemize}
\item 1ère possibilité: $\{1,1,2,5,5,20\} \rightarrow 6$ pièces
\item 2ième possibilité: $\{2,2,10,20\} \rightarrow 4$ pièces
\end{itemize}
\bigskip

\item Algorithme de la caissière: A chaque itération, ajouter une
  pièce de la plus grande valeur qui ne dépasse pas la somme restant à rembourser
\item Exemple: 49 cents $\rightarrow \{20,20,5,2,2\}$ (5 pièces)
\end{itemize}

\note{Demander à l'un d'entre eux comment il ferait pour rendre la monnaie sur un montant donné.}

\end{frame}

\begin{frame}{Implémentation}

\begin{itemize}
\item Algorithme de la caissière: A chaque itération, ajouter une
  pièce de la plus grande valeur qui ne dépasse pas la somme restant à rembourser
\end{itemize}

%% \begin{columns}
%% \begin{column}{5cm}
%% {\small
%% \begin{center}
%% \fcolorbox{white}{Lightgray}{%
%%       \begin{codebox}
%%         \Procname{$\proc{CoinchangingGreedy}(x,c,n)$}
%%         \li \Comment $c[1\twodots n]$ contains the $n$ coin values in increasing order
%%         \li Let $S$ the set of coins to give to the customer
%%         \li $S=\emptyset$
%%         \li \While $x\neq 0$\Do
%%         \li  $k=$ the largest integer such that $c_k\leq x$
%%         \li  \If $k\isequal 0$
%%         \li  \Then \Return ``No solution found''\End
%%         \li  $x=x-c[k]$
%%         \li  $S=S\cup \{k\}$\End
%%         \li \Return $S$
%%       \end{codebox}}
%% \end{center}
%% }
%% \end{column}
%% \begin{column}{5cm}
{\small
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{CoinchangingGreedy}(x,c,n)$}
        \li \Comment $c[1\twodots n]$ contains the $n$ coin values in decreasing order
        \li Let $s[1\twodots n]$ be a new table
        \li \Comment s[i] is the number of $i$th coin in solution
        \li $CoinCount=0$
        \li \For $i=1$ \To $n$ \Do
        \li  $s[i]=\lfloor x/c[i]\rfloor$
        \li  $x=x - s[i]*c[i]$
        \li  $CoinCount=CoinCount+s[i]$\End
        \li \Return $(s, CoinCount)$
      \end{codebox}}
\end{center}
}
%% \end{column}
%% \end{columns}

\begin{itemize}
\item Complexité: $O(n)$ (sans compter le tri des pièces)
\item Cet algorithme permet-il de trouver une solution optimale?
\end{itemize}

\end{frame}

\begin{frame}{Analyse de $\proc{CoinChangingGreedy}$}

\alert{Théorème:} l'algorithme $\proc{CoinChangingGreedy}$ est optimal pour $c=[20,10,5,2,1]$

\bigskip

\alert{Preuve:}
\begin{itemize}
\item Soit $S^*(x)$ l'ensemble optimal de pièces pour un montant $x$ et soit $c^*$ le plus grand $c[i]\leq x$. On doit montrer que:
\begin{enumerate}
\item $S^*(x)$ contient $c^*$\hfill{\it (propriété des choix gloutons optimaux)}
\item $S^*(x)=\{c^*\}\cup S^*(x-c^*)$\hfill{\it (propriété de sous-structure optimale)}
\end{enumerate}

\bigskip

\item Propriété (2) découle directement de (1)
\begin{itemize}
\item $S^*(x)$ contient $c^*$ par (1)
\item Donc $S^*(x)\setminus\{c^*\}$ représente le change pour un montant de $x-c^*$
\item Ce change doit être optimal sinon $S'=\{c^*\}\cup S^*(x-c^*)$ serait une meilleure solution que $S^*(x)$ pour un montant de $x$
\item On a donc $S^*(x)=\{c^*\}\cup S^*(x-c^*)$
\end{itemize}

\end{itemize}

\end{frame}

\begin{frame}
\begin{itemize}
\item Propriété (1): $S^*(x)$ contient $c^*$
\begin{itemize}
\item Avec $c=[20,10,5,2,1]$, une solution optimale ne contient jamais:
\begin{itemize}
\item plus d'une pièce de 1, 5, ou de 10 (car $2\times 1=2$, $2\times 5=10$, $2\times 10=20$)
\item plus de deux pièces de 2 (car $3\times 2=5+1$)
\end{itemize}
\item Analysons les différents cas pour $x$:
\begin{itemize}
\item[$x=1$:] $c^*=1$, meilleure solution $S^*(x)=\{1\}$ contient $c^*$
\item[$2\leq x<5$:] $c^*=2$, avec un seul 1, on ne peut pas obtenir $x$ $\Rightarrow c^*\in S^*(x)$
\item[$x=5$:] $c^*=5$, meilleure solution $S^*(x)=\{5\}$ contient $c^*$
\item[$5< x<10$:] $c^*=5$, avec un seul 1, et deux 2, on ne peut pas obtenir $x$ $\Rightarrow c^*\in S^*(x)$
\item[$x=10$:] $c^*=10$, meilleure solution $S^*(x)=\{10\}$ contient $c^*$
\item[$10<x<20$:] $c^*=10$, avec un seul 1, deux 2, et 1 seul 5, on ne peut pas obtenir $x$ $\Rightarrow c^*\in S^*(x)$
\item[$x=20$:] $c^*=20$, meilleure solution  $S^*(x)=\{20\}$ contient $c^*$
\item[$x>20$:] $c^*=20$, avec un seul 1, deux 2, 1 seul 5 et 1 seul 10, on ne peut pas obtenir $x$ $\Rightarrow c^*\in S^*(x)$
\end{itemize}
\item $S^*(x)$ contient donc toujours bien $c^*$
\end{itemize}
\end{itemize}\qed

\end{frame}

\begin{frame}{Analyse de $\proc{CoinChangingGreedy}$}
\begin{itemize}
\item L'approche greedy n'est correcte que pour certains choix particuliers de valeurs de pièces
\begin{itemize}
\item ok pour la plupart des monnaies courantes, euros, dollars\ldots
\end{itemize}
\item Contre-exemple: $C=[1,10,21,34,70,100]$ (valeurs de timbres aux USA) et $x=140$
\begin{itemize}
\item Algorithme glouton: $100,34,1,1,1,1,1,1$
\item Solution optimale: $70,70$
\end{itemize}
\bigskip
\item Solution pour résoudre le cas général: programmation dynamique
\item Très proche du problème de découpage de tige et du sac à dos
\end{itemize}

\bigskip

{\it (Exercice: écrivez une fonction $\proc{CoinChangeDP}$)}

\end{frame}

\subsection{Exemple 2: sélection d'activités}

\begin{frame}{Exemple 2: sélection d'activités}
\begin{itemize}
\item Un salle est utilisée pour différentes activités
\begin{itemize}
\item Soit $S=\{a_1, a_2,\ldots,a_n\}$ un ensemble de $n$ activités
\item $a_i$ démarre au temps $s_i$ et se termine au temps $f_i$
\item Deux activités $a_i$ et $a_j$ sont \alert{compatibles} si soit $f_i\leq s_j$, soit $f_j\leq s_i$
\end{itemize}
Problème: trouver le plus grand sous-ensemble de tâches compatibles
\item Exemple:
\centerline{\includegraphics[width=5cm]{Figures/06-activityselection-table.pdf}}

\centerline{\includegraphics[width=9cm]{Figures/06-activityselection-graph.pdf}}

\end{itemize}
\note{Solutions optimales: par exemple: $a_1, a_3, a_6, a_8$}
\end{frame}

\begin{frame}{Sélection d'activités: approche gloutonne}


\begin{itemize}
\item Schéma d'une solution gloutonne:
\begin{itemize}
\item définir un ordre ``naturel'' sur les activités
\item sélectionner les activités dans cet ordre pour autant qu'elles soient compatibles avec celles déjà choisies
\end{itemize}
\item Exemples: trier les activités selon $s_i$ (début), selon $f_i$ (fin), selon $f_i-s_i$ (durée), nombre de conflits avec d'autres activités...
\item<2> Montrer par des contre-exemples que seul le tri selon $f_i$ fonctionne
\end{itemize}

\centerline{\includegraphics<2>[width=7cm]{Figures/04-activity-sorted.pdf}}

\note{\centerline{\includegraphics[width=10cm]{Figures/06-activity-contre-exemples.pdf}}}

\end{frame}

\begin{frame}{Sélection d'activités: approche gloutonne}
\begin{itemize}
\item Considérer les activités par ordre croissant de $f_i$ et sélectionner chaque activité compatible avec celles déjà prises
\item Implémentations: en supposant $s$ et $f$ ordonnés selon $f$
\end{itemize}

\begin{columns}
\begin{column}{6cm}
{\scriptsize
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Rec-activity-selector}(s,f,k,n)$}
        \li $m=k+1$
        \li \While $m\leq n$ and $s[m]<f[k]$
        \li \Do $m=m+1$\End
        \li \If $m\leq n$
        \li \Then \Return $\{a_m\}\cup...$\Indentmore 
        \li $...\proc{Rec-activity-selector}(s,f,m,n)$\End
        \li \Else \Return $\emptyset$\End
      \end{codebox}}
\end{center}
Appel initial: $\proc{Rec-activity-selector}(s,f,0,s.length)$
}
\end{column}
\begin{column}{4cm}
{\scriptsize
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Iter-activity-selector}(s,f)$}
        \li $n=s.length$
        \li $A=\{a_1\}$
        \li $k=1$
        \li \For $m=2$ \To $n$
        \li \Do \If $s[m]\geq f[k]$
        \li \Then $A=A\cup\{a_m\}$
        \li $k=m$\End\End
        \li \Return $A$
      \end{codebox}}
\end{center}
~\\
~\\
}
\end{column}
\end{columns}

\bigskip

\begin{itemize}
\item Complexité: $\Theta(n)$ ($+\Theta(n\log n)$ pour le tri selon $f_i$)
\end{itemize}

\end{frame}

\begin{frame}{Sélection d'activités: analyse}
\begin{itemize}
\item La solution gloutonne est-elle correcte ?

\bigskip

\item \alert{1. Propriété des choix gloutons optimaux:} Soit $a_x\in S$ tel que $f_x\leq f_i$ pour tout $a_i\in S$. Il existe une solution optimale $OPT^*$ qui contient $a_x$.
\item \alert{Preuve:}
\begin{itemize}
\item Soit une solution optimale $OPT$ telle que $a_x\notin OPT$
\item Soit $a_m$ l'activité qui se termine en premier dans $OPT$
\item Construisons $OPT^*=(OPT\setminus \{a_m\})\cup \{a_x\}$
\item $OPT^*$ est valide:
\begin{itemize}
\item Toute activité $a_i\in OPT\setminus \{a_m\}$ débute en un temps $s_i\geq f_m$
\item Par définition de $a_x$, $f_m\geq f_x$ et donc pour tout activité $a_i$, $s_i\geq f_x$
\item Toute activité $a_i$ est donc compatible avec $a_x$
\end{itemize}
\item $OPT^*$ est donc optimale puisque $|OPT^*|=|OPT|$
\end{itemize}\qed
\end{itemize}

\note{Montrer sur le schéma trié}

\end{frame}

\begin{frame}{Sélection d'activités: analyse}
\begin{itemize}
\item La solution gloutonne est-elle correcte ?

\bigskip

\item \alert{2. Propriété de sous-structure optimale:} Soit $a_x\in S$ le choix glouton et $S'=\{a_i|s_i\geq f_x\}$ les activités de $S$ compatibles avec $a_x$. Soit $OPT^*=\{a_x\}\cup OPT'$. Si $OPT'$ est une solution optimale pour $S'$ alors $OPT^*$ est une solution optimale pour $S$.
\item \alert{Preuve:}
\begin{itemize}
\item Soit $OPT$ une solution optimale pour $S$
\item Si $OPT^*$ n'est pas une solution optimale pour $S$, alors $|OPT^*|<|OPT|$ et donc aussi $|OPT'|<|OPT|-1$
\item Soit $a_m$ l'activité qui se termine en premier dans $OPT$ et $\bar{S}=\{a_i|s_i\geq f_m\}$
\item Par construction, $OPT\setminus\{a_m\}$ est une solution pour $\bar{S}$
\item Par construction, $\bar{S}\subseteq S'$ et $OPT\setminus\{a_m\}$
  est une solution valide pour $S'$ (pas nécessairement optimale)
\item Ce qui veut dire qu'il existe une solution pour $S'$ de taille $|OPT|-1$, ce qui contredit  $|OPT'|<|OPT|-1$ et $OPT'$ optimal pour $S'$ (par hypothèse).
\end{itemize}\qed
\end{itemize}

\end{frame}

\begin{frame}{Problèmes similaires}

D'autres problèmes similaires pour lesquels il existe un algorithme glouton:
\begin{itemize}
\item Allocation de resources:
\begin{itemize}
\item Etant donnée un ensemble d'activités $S$ avec leurs temps de début et de fin, trouver le nombre minimum de salles permettant de les réaliser toutes
%\item Solution gloutonne: trier les activités par ordre croissant du temps de départ
\end{itemize}

\bigskip

\item Planification de tâches:
\begin{itemize}
\item Soit un ensemble de tâches avec leur durée et l'instant auquel elles doivent chacune être terminées (leur deadline)
\item Sachant qu'on ne peut exécuter qu'une seule tâche simultanément,
  trouver l'ordonnancement de ces tâches qui minimise le dépassement maximal des deadlines associées aux tâches (latence).
%\item Solution gloutonne: trier les tâches en fonction de leur deadline
\end{itemize}
\end{itemize}

\note{Revenir à ma figure pour la sélection d'activité}

\end{frame}

\subsection{Exemple 3: problème du sac à dos}

\begin{frame}{Exemple 3: problème du sac à dos}

Rappel: problème (0/1) du sac à dos:
\begin{itemize}
\item Soit un ensemble $S$ de $n$ objets de poids $p_i>0$ et de valeur $v_i>0$
\item Trouver $x_1, x_2, \ldots, x_n \in \{0,1\}$ tels que:
\begin{itemize}
\item $\sum_{i=1}^n x_i\cdot p_i\leq W$, et
\item $\sum_{i=1}^n x_i\cdot v_i$ est maximal.
\end{itemize}
\end{itemize}

\bigskip

Solution par programmation dynamique: $\Theta(n W)$

\bigskip

Peut-on le résoudre par une approche gloutonne ?


\note{Leur demander de venir avec une solution.}

\end{frame}


\begin{frame}{Programmation dynamique versus approche gloutonne}
\begin{itemize}
\item Rappel du transparent \pageref{part6:knapsack}:
\begin{itemize}
\item soit $M(k,w)$, $0\leq k\leq n$ et $0\leq w\leq W$, le bénéfice
  maximum qu'on peut obtenir avec les objets 1,\ldots,$k$ de $S$ et un
  sac à dos de charge maximale $w$. On a:
  {\small \[M(k,w)=\left\{\begin{array}{ll} 0 & \mbox{ si
    }i=0\\ M(k-1,w) & \mbox{ si }
    p_i>w\\ \max\{M(k-1,w),v_k+M(k-1,w-p_k)\} & \mbox{ sinon}
\end{array}
\right.
\]}
\end{itemize}
\item Approche gloutonne: consisterait à remplacer le \alert{max} par le choix qui nous semble le meilleur localement
\item Quels choix possibles ?
\begin{itemize}
\item Le moins lourd, le plus lourd ?
\item Le moins coûteux, le plus coûteux ?
\item Le meilleur rapport valeur/poids ?
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Approche gloutonne}

\begin{itemize}
\item Idée d'algorithme:
\begin{itemize}
\item Ajouter à chaque itération l'objet de rapport $\frac{v_i}{p_i}$ maximal qui rentre dans le sac
\item Implémentation très proche du problème de change: $\Theta(n\log n)$
\end{itemize}
\item Est-ce que ça fonctionne ? Non !
%\begin{columns}
%\begin{column}{5cm}
%Solution optimale: $\{4, 3\}$\\
%Bénéfice: $22+18=40$
%\end{column}
%\begin{column}{5cm}
\begin{center}
\begin{tabular}{cccc}
$i$ & $v_i$ & $p_i$ & $v_i/p_i$\\
\hline
1 & 1 & 1 & 1\\
2 & 6 & 2 & 3\\
3 & 18 & 5 & 3,6\\
4 & 22 & 6 & 3,7\\
5 & 28 & 7 & 4\\
\end{tabular}
\end{center}
%\end{column}
%\end{columns}
W=11:
\begin{itemize}
\item Solution greedy: $\{5,2,1\} \Rightarrow$ valeur=35
\item Solution DP: $\{4,3\} \Rightarrow$ valeur=40
\end{itemize}
%\item Peut-on caractériser de combien on se trompe ?
\end{itemize}
\end{frame}

\begin{frame}{Problème fractionnel du sac à dos (fractional knapsack)}

Par rapport au problème 0/1, il est maintenant permis d'inclure
des fractions d'objets ($\leq 1$):
\begin{itemize}
\item Soit un ensemble $S$ de $n$ objets de poids $p_i>0$ et de valeur $v_i>0$
\item Trouver $x_1, x_2, \ldots, x_n \in {\color{red}[0,1]}$ tels que:
\begin{itemize}
\item $\sum_{i=1}^n x_i\cdot p_i\leq W$, et
\item $\sum_{i=1}^n x_i\cdot v_i$ est maximal.
\end{itemize}
\end{itemize}
\bigskip
{\small
Exemple:
\vspace{-0.5cm}
\begin{center}\small
\begin{tabular}{cccc}
$i$ & $v_i$ & $p_i$ & $v_i/p_i$\\
\hline
1 & 1 & 1 & 1\\
2 & 6 & 2 & 3\\
3 & 18 & 5 & 3,6\\
4 & 22 & 6 & 3,7\\
5 & 28 & 7 & 4\\
\end{tabular}
\end{center}
W=11:
\begin{itemize}
\item Solution optimale 0/1: $x_1=0$, $x_2=0$, $x_3=1$, $x_4=1$, $x_5=0$ $\Rightarrow$ valeur=40
\item Solution optimale fractionnelle: $x_1=0$, $x_2=0$, $x_3=0$, $x_4=2/3$, $x_5=1$ $\Rightarrow$ valeur=42,66
\end{itemize}
}
\end{frame}


\begin{frame}{Algorithme glouton}

\begin{itemize}
\item Pour la version fractionnelle, l'algorithme glouton est optimal
\item Implémentation:

\bigskip

{\small
\begin{center}
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{FracKnapSack}(p,v,n,W)$}
        \li \Comment {\color{red}Assume the objects are sorted according to $v[i]/p[i]$}
        \li Let $x[1\twodots n]$ a new table
        \li $w=0$
        \li \For $i=1$ \To $n$
        
        \li \Do $d=min(p[i],W-w)$
        \li $w\gets w+d$
        \li $x[i]=d/p[i]$\End
        \li \Return $x$
      \end{codebox}}
\end{center}
}
\bigskip

\item Complexité: $\Theta(n)$ (+ $\Theta(n\log n)$ pour le tri)
\end{itemize}

\end{frame}

\begin{frame}{Correction}

\alert{Théorème:} Le problème fractionnel du sac à dos possède la propriété des choix gloutons optimaux

\bigskip

\alert{Preuve:}
\begin{itemize}
\item Soit deux objets $i$ et $j$ tels que
$$\frac{v_i}{p_i}>\frac{v_j}{p_j}$$
\item Etant donné un choix $(x_1,x_2,\ldots,x_n)$, on le transforme en $(x'_1,x'_2,\ldots, x'_n)$ tel que:
\begin{itemize}
\item $\forall k\in [1,n]\setminus\{i,j\}: x'_k=x_k,$
\item $x'_i=x_i+\frac{\Delta}{p_i}$, et
\item $x'_j=x_j-\frac{\Delta}{p_j}$,
\end{itemize}
où $\Delta=\min(p_i(1-x_i),p_jx_j)$.
\item Cette transformation ne modifie pas le poids total, mais améliore le bénéfice.
\item On en déduit qu'il est toujours avantageux de prendre la fraction maximale de l'objet $i$ possédant le plus grand rapport $\frac{v_i}{p_i}$.\qed
\end{itemize}

\end{frame}

\begin{frame}{Algorithme glouton: résumé}

\begin{itemize}
\item Très efficaces quand ils fonctionnent. Simples et faciles à
  implémenter
\item Ne fonctionnent pas toujours. Leur correction peut être assez
  difficile à prouver
\end{itemize}

\bigskip

Applications:
\begin{itemize}
\item Arbre de couverture minimal (voir partie 7)
\item Plus court chemin dans un graphe (algorithme de Dijkstra)
\item Allocation de resources
\item Codage de Huffman
\item \ldots
\end{itemize}

\end{frame}

\begin{frame}{Approche gloutonne versus programmation dynamique}

\begin{itemize}
\item Tous deux nécessitent la propriété de sous-structure optimale

\bigskip

\item Les algorithmes gloutons nécessitent que la propriété de choix gloutons optimaux soit satisfaite
\begin{itemize}
\item On n'a pas besoin de solutionner plus d'un sous-problème
\item Le choix glouton est fait \alert{avant} de résoudre le sous-problème
\item Il n'y a pas besoin de stocker les résultats intermédiares
\end{itemize}

\bigskip

\item La programmation dynamique marche sans la propriété des choix gloutons optimaux
\begin{itemize}
\item On doit solutionner plusieurs sous-problèmes et choisir dynamiquement l'un deux pour obtenir la solution globale
\item La solution doit être assemblée ``bottom-up''
\item Les sous-solutions aux sous-problèmes sont réutilisées et doivent donc être stockées
\end{itemize}
\end{itemize}

\end{frame}

\subsection{Exemple 4: codage de Huffman}

\begin{frame}{Exemple 4: codage de Huffman}
\begin{itemize}
\item Soit une séquence $S$ très longue définie sur base de 6 caractères: a, b, c, d, e et f
\begin{itemize}
\item Par exemple, $n=|S|=10^9$
\end{itemize}

\bigskip

\item Quelle est la manière la plus efficace de stocker cette séquence ?

\bigskip

\item Première approche: encoder chaque symbole par un mot binaire de
  longueur fixe:

\begin{center}
\begin{tabular}{c|cccccc}
Symbole & a & b & c & d & e & f\\
\hline
Codage & 000 & 001 & 010 & 011 & 100 & 101\\
\end{tabular}
\end{center}

\begin{itemize}
\item 6 symboles nécessitent 3 bits par symbole
\item $3\times 10^9/8=3.75\times 10^8$bytes (un peu moins de 400Mb)
\end{itemize}
\item Peut-on faire mieux ?
\end{itemize}

\note{Observer que pour e et f par exemple, il n'y a pas besoin de 3 symboles}
\end{frame}

\begin{frame}{Idée}

\begin{itemize}
\item Codage avec des mots de longueur fixe:
\begin{center}
\begin{tabular}{c|cccccc}
Symbole & a & b & c & d & e & f\\
\hline
Codage & 000 & 001 & 010 & 011 & 100 & 101\\
\end{tabular}
\end{center}

\item Observation: l'encodage de e et f est redondant:
\begin{itemize}
\item Le second bit ne nous aide pas à distinguer e de f
\item En d'autres termes, si le premier bit est 1, le second ne nous donne pas d'information et peut être supprimé
\end{itemize}
\item Suggère de considérer un codage avec des mots binaires de
  longueurs variables
\begin{center}
\begin{tabular}{c|cccccc}
Symbole & a & b & c & d & e & f\\
\hline
Codage & 000 & 001 & 010 & 011 & {\color{red}10}& {\color{red}11}\\
\end{tabular}
\end{center}
\item Encodage et décodage sont bien définis et non ambigüs
\item Permet de gagner $n_e+n_f$ bits, où $n_e$ et $n_f$ sont les nombres de e et de f dans la séquence
\end{itemize}
\end{frame}

\begin{frame}{Définition du problème}
\begin{itemize}
\item Soit un ensemble de symboles $C$ et $f(c)$ la fréquence du symbole $c\in C$.
\item Trouver un code $E: C\rightarrow \{0,1\}^*$ tel que
\begin{itemize}
\item $E$ est un code \alert{sans préfixe}
\begin{itemize}
\item Aucun mot de code $E(c_1)$ n'est le préfixe d'un autre mot de code $E(c_2)$
\end{itemize}
\item La longueur moyenne des mots de code est \alert{minimale}
$$B(S)=\sum_{c\in C} f(c)|E(c)|$$
($n B(S)$ est la longueur de l'encodage de $S$)
\end{itemize}
\item Exemple:
\begin{center}\small
\begin{tabular}{c|cccccc|c}
c & a & b & c & d & e & f & \\
f(c) & 45\% & 13\% & 12\% & 16\% & 9\% & 5\% & $B(S)$\\
\hline
Code 1 & 000 & 001 & 010 & 011 & 100& 101 & 3.00\\
Code 2 & 000 & 001 & 010 & 011 & 10& 11 & 2.86\\
Code 3 & 0 & 101 & 100 & 111 & 1101 & 1100 & 2.24\\
\end{tabular}
\end{center}
\end{itemize}

\end{frame}

\begin{frame}{Code sans préfixe}

\centerline{\includegraphics[width=5cm]{Figures/06-huffman-tree1.pdf}~~~\includegraphics[width=3.7cm]{Figures/06-huffman-tree2.pdf}}

\begin{itemize}
\item Un code sans préfixe peut toujours se représenter sous la forme d'une arbre binaire
\begin{itemize}
\item Chaque feuille est associée à un symbole
\item Le chemin de la racine à une feuille est le code du symbole
\item La fréquence d'un n\oe ud est la fréquence du préfixe
\end{itemize}
\item Un code optimal est toujours représenté par un arbre binaire entier {\it (Pourquoi ?)}
\end{itemize}

\end{frame}

\begin{frame}{Algorithme glouton}

On peut montrer que le codage optimal peut être obtenu par un
  algorithme glouton
\begin{itemize}
\item On construit l'arbre de bas en haut en partant des feuilles
\item A chaque étape, on fait le choix ``glouton'' de fusionner les deux n\oe uds les moins fréquents (symboles ou préfixes)
\end{itemize}

\bigskip

Idée de la preuve (pour information):
\begin{itemize}
\item Choix gloutons optimaux:
\begin{itemize}
\item Il existe un code sans préfixe optimal où les deux symboles les moins fréquents sont frères et à la profondeur maximale
\item Par l'absurde: si un tel code n'existait pas, on pourrait l'obtenir en échangeant la position des deux symboles les moins fréquents avec les feuilles les plus profondes sans augmenter $B(S)$
\end{itemize}
\item Sous-structure optimale:
\begin{itemize}
\item Si l'arbre qui a pour feuille le nouveau n\oe ud issu de la fusion gloutonne est optimal, l'arbre complet est optimal
\item Plus difficile à montrer
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Algorithme glouton: exemple}

\centerline{\includegraphics[width=11cm]{Figures/06-huffman-tree-build.pdf}}

\note{Demander comment ils l'implémenteraient}
\end{frame}

\begin{frame}{Algorithme glouton: implémentation}

\begin{center}
{\small
\fcolorbox{white}{Lightgray}{%
      \begin{codebox}
        \Procname{$\proc{Huffman}(C)$}
        \li $n=|C|$
        \li $Q=$"create a min-priority queue from $C$"
        \li \For $i=1$ \To $n-1$
        \li \Do Allocate a new node $z$
        \li $z.left=\proc{Extract-Min}(Q)$
        \li $z.right=\proc{Extract-Min}(Q)$
        \li $z.freq=z.left.freq+z.right.freq$
        \li $\proc{Insert}(Q,z)$\End
        \li \Return $\proc{Extract-min}(Q)$
      \end{codebox}}
}
\end{center}

\bigskip

\begin{itemize}
\item Implémentation avec une file à priorité
\item Complexité: $O(n\log n)$ si $Q$ est implémentée avec un tas (min)
\begin{itemize}
\item Ligne 2: $O(n)$ si on utilise $\proc{Build-min-heap}$
\item Ligne 8: $O(\log n)$ (répétée $n-1$ fois)
\end{itemize}
\end{itemize}

\end{frame}

%% \begin{frame}{Conclusion}

%% \begin{itemize}
%% \item Trois méthodes de résolutions de problèmes
%% \item Plusieurs exemples de problèmes 
%% \item Des problèmes pouvant être 
%% \end{itemize}

%% \end{frame}
